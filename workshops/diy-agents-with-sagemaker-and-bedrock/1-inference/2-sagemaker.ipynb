{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038eb9f-d925-437b-8f2e-e9b4e78c8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker boto3 litellm aiohttp -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b5ebc-10ff-42e2-80f5-a28da0afb6d7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>⚠️ <b>Important:</b> Please restart the kernel after installing the dependencies. ⚠️</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21051e4e-64ea-4c7a-b18e-5a1d069527af",
   "metadata": {},
   "source": [
    "## Deploy the model from SageMaker JumpStart on a SageMaker Inference endpoint\n",
    "\n",
    "> Note: skip the cell below if you have already deployed your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd73517-e000-45cc-b11c-e2cee2ed94e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.enums import EndpointType\n",
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "\n",
    "\n",
    "resources = ResourceRequirements(\n",
    "    requests = {\n",
    "        \"num_accelerators\": 4, # Number of accelerators required\n",
    "        \"memory\": 96*1024,  # Minimum memory required in Mb (required)\n",
    "        \"copies\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = JumpStartModel(\n",
    "    model_id=\"huggingface-llm-mistral-small-24B-Instruct-2501\", model_version=\"2.0.1\",\n",
    "    instance_type=\"ml.g5.12xlarge\"\n",
    ")\n",
    "predictor = model.deploy(\n",
    "    accept_eula=True,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    serializer=JSONSerializer(), deserializer=JSONDeserializer(),\n",
    "    endpoint_type=EndpointType.INFERENCE_COMPONENT_BASED,\n",
    "    resources=resources,\n",
    "    managed_instance_scaling={\n",
    "        \"MinInstanceCount\": 0,\n",
    "        \"MaxInstanceCount\": 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "component_name = predictor.component_name\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "print(f\"Inference component name: {component_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90845068",
   "metadata": {},
   "source": [
    "**NOTE:** deployment will take 5~7 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18881de7-0fc6-4490-9992-a12fd05da7eb",
   "metadata": {},
   "source": [
    "## Test it\n",
    "\n",
    "### Using the Predictor object from the SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0d089-1492-4615-b952-d12e96278dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    predictor\n",
    "except:\n",
    "    import boto3\n",
    "    from sagemaker.session import Session\n",
    "    from sagemaker.predictor import Predictor\n",
    "    from sagemaker.serializers import JSONSerializer\n",
    "    from sagemaker.deserializers import JSONDeserializer\n",
    "    \n",
    "    endpoint_name = \"YOUR-ENDPOINT-NAME-HERE\"\n",
    "    component_name = \"YOUR-INFERENCE-COMPONENT-NAME-HERE\"\n",
    "\n",
    "    boto_session = boto3.session.Session(region_name=boto3.Session().region_name)\n",
    "    session = Session(boto_session=boto_session)\n",
    "    \n",
    "    predictor = Predictor(\n",
    "        sagemaker_session=session,\n",
    "        endpoint_name=endpoint_name, component_name=component_name,\n",
    "        serializer=JSONSerializer(), deserializer=JSONDeserializer()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99d49a-6b06-49cb-b32c-412e4a0a6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = \"What is the town of Bari, Italy, known for?\"\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 4*1024,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "response = predictor.predict(payload)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712cd57-f8d8-4f60-8813-91e2951092cb",
   "metadata": {},
   "source": [
    "### Using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e86c2f-b0cf-428e-b06b-4ad74637c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": \"What is the town of Bari, Italy, known for? Provide a short answer.\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 4*1024,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "}\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime', region_name=boto3.Session().region_name)\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=component_name or None,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7fd8e-de2c-4353-8ea9-18455efc7db7",
   "metadata": {},
   "source": [
    "### Using Boto3 and the Messages API (for compatible models only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff55c3-5610-4298-9880-a83668c34a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and honest assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the town of Bari, Italy, known for? Provide a short answer.\"}\n",
    "    ],\n",
    "    \"max_tokens\": 4*1024,\n",
    "    \"parameters\": {\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "    }\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=component_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee0c9e7-c4b4-4401-a666-0f561bb8f24e",
   "metadata": {},
   "source": [
    "## Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f2f8e-e740-46b8-b136-666de9613c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "\n",
    "response = completion(\n",
    "    model=f\"sagemaker/{endpoint_name}\", \n",
    "    model_id=component_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and honest assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the town of Bari, Italy, known for? Provide a short answer.\"}\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361da444",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Important:</b> as of LiteLLM v1.67.2, `sagemaker_chat` provider does not not correctly pass the inference component name, causing `HTTPStatusError: Client error '400 Bad Request'`. Please use `sagemaker` provider instead.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
