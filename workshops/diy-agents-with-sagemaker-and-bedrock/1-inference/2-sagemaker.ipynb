{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038eb9f-d925-437b-8f2e-e9b4e78c8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker boto3 litellm -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b5ebc-10ff-42e2-80f5-a28da0afb6d7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>⚠️ <b>Important:</b> Please restart the kernel after installing the dependencies. ⚠️</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21051e4e-64ea-4c7a-b18e-5a1d069527af",
   "metadata": {},
   "source": [
    "## Deploy the model from SageMaker JumpStart on a SageMaker Inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd73517-e000-45cc-b11c-e2cee2ed94e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.enums import EndpointType\n",
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "\n",
    "\n",
    "resources = ResourceRequirements(\n",
    "    requests = {\n",
    "        \"num_accelerators\": 4, # Number of accelerators required\n",
    "        \"memory\": 96*1024,  # Minimum memory required in Mb (required)\n",
    "        \"copies\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = JumpStartModel(\n",
    "    model_id=\"huggingface-llm-mistral-small-24B-Instruct-2501\", model_version=\"*\",\n",
    "    instance_type=\"ml.g5.12xlarge\"\n",
    ")\n",
    "predictor = model.deploy(\n",
    "    accept_eula=True,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    serializer=JSONSerializer(), deserializer=JSONDeserializer(),\n",
    "    endpoint_type=EndpointType.INFERENCE_COMPONENT_BASED,\n",
    "    resources=resources,\n",
    "    managed_instance_scaling={\n",
    "        \"MinInstanceCount\": 0,\n",
    "        \"MaxInstanceCount\": 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18881de7-0fc6-4490-9992-a12fd05da7eb",
   "metadata": {},
   "source": [
    "## Test it\n",
    "\n",
    "### Using the Predictor object from the SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0d089-1492-4615-b952-d12e96278dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    predictor\n",
    "except:\n",
    "    from sagemaker.predictor import Predictor\n",
    "    from sagemaker.serializers import JSONSerializer\n",
    "    from sagemaker.deserializers import JSONDeserializer\n",
    "    \n",
    "    endpoint_name = \"REPLACE-WITH-ENDPOINT-NAME\"\n",
    "    component_name = \"REPLACE-WITH-INFERENCE-COMPONENT-NAME\"\n",
    "    \n",
    "    predictor = Predictor(\n",
    "        endpoint_name=endpoint_name, component_name=component_name,\n",
    "        serializer=JSONSerializer(), deserializer=JSONDeserializer()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99d49a-6b06-49cb-b32c-412e4a0a6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = \"What is the town of Bari, Italy, known for?\"\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 4000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "response = predictor.predict(payload)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712cd57-f8d8-4f60-8813-91e2951092cb",
   "metadata": {},
   "source": [
    "### Using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e86c2f-b0cf-428e-b06b-4ad74637c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": \"What is the town of Bari, Italy, known for? Provide a short answer.\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 4*1024,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "}\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=component_name or None,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7fd8e-de2c-4353-8ea9-18455efc7db7",
   "metadata": {},
   "source": [
    "### Using Boto3 and the Messages API (for compatible models only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff55c3-5610-4298-9880-a83668c34a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and honest assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the town of Bari, Italy, known for? Provide a short answer.\"}\n",
    "    ],\n",
    "    \"max_tokens\": 4*1024,\n",
    "    \"parameters\": {\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "    }\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=component_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee0c9e7-c4b4-4401-a666-0f561bb8f24e",
   "metadata": {},
   "source": [
    "## Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f2f8e-e740-46b8-b136-666de9613c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "    model=f\"sagemaker/{endpoint_name}\", \n",
    "    model_id=component_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and honest assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the town of Bari, Italy, known for? Provide a short answer.\"}\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361da444",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Important:</b> as of LiteLLM v1.67.2, `sagemaker_chat` provider does not not correctly pass the inference component name, causing `HTTPStatusError: Client error '400 Bad Request'`. Please use `sagemaker` provider instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e8804-4e47-404f-88a5-2bcf76b45419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "    model=f\"sagemaker_chat/{endpoint_name}\",\n",
    "    model_id=component_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and honest assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the town of Bari, Italy, known for? Provide a short answer.\"}\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a563b-446d-460e-a2a1-3aa0b8419cef",
   "metadata": {},
   "source": [
    "## Function calling with Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59bbd9-294f-43d8-af90-790fd0387754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_song(sign: str) -> dict:\n",
    "    \"\"\"Get the most popular song played on a radio station.\"\"\"\n",
    "    sign = sign.upper()\n",
    "    return {\n",
    "        \"sign\": sign,\n",
    "        \"song\": \"In the End\",\n",
    "        \"artist\": \"Linkin Park\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629b9d9-eb4c-4f4a-9cf4-f38f55832ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_description = {\n",
    "    \"name\": \"top_song\",\n",
    "    \"description\": \"Get the most popular song played on a radio station.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sign\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The call sign for the radio station for which you want the most popular song. Example calls signs are WZPZ and WKRP.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"sign\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107b94e-da09-4873-b6e7-30dbc1abb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\n",
    "            \"You are a helpful assistant with access to these tools:\\n\\n\"\n",
    "            f\"{tools_description}\\n\"\n",
    "            \"Choose the appropriate tool based on the user's question. \"\n",
    "            \"If no tool is needed, reply directly.\\n\\n\"\n",
    "            \"IMPORTANT: When you need to use a tool, you must ONLY respond with \"\n",
    "            \"the exact JSON object format below, nothing else:\\n\"\n",
    "            \"{\\n\"\n",
    "            '    \"tool\": \"tool-name\",\\n'\n",
    "            '    \"arguments\": {\\n'\n",
    "            '        \"argument-name\": \"value\"\\n'\n",
    "            \"    }\\n\"\n",
    "            \"}\\n\\n\"\n",
    "            \"After receiving a tool's response:\\n\"\n",
    "            \"1. Transform the raw data into a natural, conversational response\\n\"\n",
    "            \"2. Keep responses concise but informative\\n\"\n",
    "            \"3. Focus on the most relevant information\\n\"\n",
    "            \"4. Use appropriate context from the user's question\\n\"\n",
    "            \"5. Avoid simply repeating the raw data\\n\\n\"\n",
    "            \"Please use only the tools that are explicitly defined above.\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d45a0e-47e2-4e61-8b4b-10f1e8bbb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": \"What is the most popular song on WZPZ?\"}\n",
    "    ],\n",
    "    \"max_tokens\": 4*1024,\n",
    "    \"parameters\": {\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "    }\n",
    "}\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=\"hf-llm-mistral-small-24b-instruct-2501-2025-04-07-10-48-04-846\",\n",
    "    InferenceComponentName=\"hf-llm-mistral-small-24b-instruct-2501-2025-04--1744023037-a1d1\",\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "content = result['choices'][0]['message']['content']\n",
    "# Regexp the JSON from the content\n",
    "import re\n",
    "match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
    "content = json.loads(match.group(0))\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecba0e-d574-4d45-83df-252e1d829acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947bdfb-242e-4dd5-98b7-a9bb0b60b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until no more tools are needed\n",
    "final_response_reached = False\n",
    "while not final_response_reached:\n",
    "    tool_name = content[\"tool\"]\n",
    "    tool_arguments = content[\"arguments\"]\n",
    "    if tool_name == \"top_song\":\n",
    "        tool_response = get_top_song(tool_arguments[\"sign\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "    payload[\"messages\"].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": json.dumps(tool_response)\n",
    "    })\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=\"hf-llm-mistral-small-24b-instruct-2501-2025-04-07-10-48-04-846\",\n",
    "        InferenceComponentName=\"hf-llm-mistral-small-24b-instruct-2501-2025-04--1744023037-a1d1\",\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    content = result['choices'][0]['message']['content']\n",
    "    match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
    "    try:\n",
    "        content = json.loads(match.group(0))\n",
    "    except:\n",
    "        final_response_reached = True\n",
    "        final_response = content\n",
    "        break\n",
    "final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ddfed-01bf-44a2-8ae3-363c5b4ddc8f",
   "metadata": {},
   "source": [
    "## Function Calling with LiteLLM\n",
    "\n",
    "> **Note**: as of v1.67.2, LiteLLM `sagemaker` and `sagemaker_chat` providers do not support tool calling. The cells below **will not** work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
