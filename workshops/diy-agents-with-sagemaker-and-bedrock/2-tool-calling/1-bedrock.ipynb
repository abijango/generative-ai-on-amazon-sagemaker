{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3 litellm aiohttp --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44498b2b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center>⚠️ <b>Important:</b> Please restart the kernel after installing the dependencies. ⚠️</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f41d5b-9ea0-42fa-88a6-eab661beded4",
   "metadata": {},
   "source": [
    "# Understanding Function/Tool Calling\n",
    "\n",
    "Modern AI agents excel at tool utilization—the ability to identify, select, and leverage appropriate tools from their available arsenal to accomplish specific tasks. These tools might include:\n",
    "\n",
    "- Database queries\n",
    "- Computational functions\n",
    "- Document processing capabilities\n",
    "- Integrations with specialized services\n",
    "\n",
    "The agent orchestrates these tools in sequence, creating workflows that seamlessly transition between different capabilities as needed. This approach allows systems to transcend the limitations of any single model or tool.\n",
    "\n",
    "Let's start with a sample tool - a very simple Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a2ad1-b58a-42e3-a5b4-6e44fd2b2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_song(sign):\n",
    "    \"\"\"Returns the most popular song for the requested station.\n",
    "    Args:\n",
    "        call_sign (str): The call sign for the station for which you want\n",
    "        the most popular song.\n",
    "\n",
    "    Returns:\n",
    "        response (json): The most popular song and artist.\n",
    "    \"\"\"\n",
    "\n",
    "    song = \"\"\n",
    "    artist = \"\"\n",
    "    if sign == 'WZPZ':\n",
    "        song = \"Elemental Hotel\"\n",
    "        artist = \"8 Storey Hike\"\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Station {sign} not found.\")\n",
    "\n",
    "    return {\n",
    "        \"song\": song, \n",
    "        \"artist\": artist\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61008585-1216-4b43-9cf6-cbeef6133a9c",
   "metadata": {},
   "source": [
    "In order for the LLM to know that it can use this tool, we have to pass the tool definition to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c013d-459d-43d8-bd73-b7ce165732ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"get_top_song\",\n",
    "                \"description\": \"Get the most popular song played on a radio station.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"sign\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The call sign for the radio station for which you want the most popular song. Example calls signs are WZPZ and WKRP.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"sign\"\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c42f5-f61a-49f9-8225-49c15ffca562",
   "metadata": {},
   "source": [
    "Now we can start conversing with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cd5f3-4b56-4670-ab13-56f7ea0be237",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What is the most popular song on WZPZ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5a24e-d9c0-4e72-8676-eb357fc8b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=boto3.Session().region_name)\n",
    "messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": input_text}]\n",
    "}]\n",
    "\n",
    "response = bedrock_client.converse(\n",
    "    modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "    messages=messages,\n",
    "    toolConfig=tool_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bacd2c1-0312-4e67-83fd-9c83faedbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_message = response['output']['message']\n",
    "messages.append(output_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf7953-e885-4922-b08a-6e76cbcf994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['output']['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099bf3e2-7460-4218-8192-a37d301e8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_request in response['output']['message']['content']:\n",
    "    if 'toolUse' in tool_request:\n",
    "        tool = tool_request['toolUse']\n",
    "        tool_name = tool['name']\n",
    "        tool_input = tool['input']\n",
    "        print(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcba3f-f916-4228-a8bb-ed02ad789c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_top_song(**tool_input)\n",
    "tool_result = {\n",
    "    \"toolUseId\": tool['toolUseId'],\n",
    "    \"content\": [{\"json\": output}]\n",
    "}\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fa029-45df-4c63-bb34-1c1312fbde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_result_message = {\n",
    "    \"role\": \"user\", \"content\": [{\"toolResult\": tool_result}]\n",
    "}\n",
    "messages.append(tool_result_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb8792-bc51-4907-b4ff-4ec796481548",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.converse(\n",
    "    modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "    messages=messages,\n",
    "    toolConfig=tool_config\n",
    ")\n",
    "output_message = response['output']['message']\n",
    "output_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47864358",
   "metadata": {},
   "source": [
    "For your ease of use, here we provide a function that calls tools until a final response is achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e796e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def converse_with_tools(user_input: str, tools: Dict[str, Any], verbose: bool = False) -> Tuple[Dict[str, Any], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Converse with a model using a tool-assisted interaction loop and track token usage.\n",
    "\n",
    "    Args:\n",
    "        user_input: Initial user query.\n",
    "        tools: Tool configuration dictionary for the model.\n",
    "        verbose: If True, print intermediate steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - Final response from the model after tool usage (if any).\n",
    "            - Dictionary with cumulative token usage.\n",
    "    \"\"\"\n",
    "    \n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def call_tool(tool_name: str, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Call a local function as a tool by name with arguments.\"\"\"\n",
    "        try:\n",
    "            return getattr(sys.modules[__name__], tool_name)(**tool_input)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error calling tool '{tool_name}': {e}\")\n",
    "\n",
    "    # Start the conversation\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_input}]\n",
    "    }]\n",
    "\n",
    "    # Initialize token usage tracking\n",
    "    total_usage = {\n",
    "        \"inputTokens\": 0,\n",
    "        \"outputTokens\": 0,\n",
    "        \"totalTokens\": 0,\n",
    "    }\n",
    "\n",
    "    def update_usage(response: Dict[str, Any]):\n",
    "        usage = response.get(\"usage\", {})\n",
    "        for key in total_usage:\n",
    "            total_usage[key] += usage.get(key, 0)\n",
    "\n",
    "    # First model call\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "        messages=messages,\n",
    "        toolConfig=tools\n",
    "    )\n",
    "    update_usage(response)\n",
    "\n",
    "    while True:\n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "\n",
    "        content = output_message.get(\"content\", [])\n",
    "        if len(content) < 2 or \"toolUse\" not in content[1]:\n",
    "            break  # No more tools to use\n",
    "\n",
    "        tool_use = content[1][\"toolUse\"]\n",
    "        tool_name = tool_use[\"name\"]\n",
    "        tool_input = tool_use[\"input\"]\n",
    "        tool_use_id = tool_use[\"toolUseId\"]\n",
    "\n",
    "        log(f\"[Tool Call] {tool_name} with input {tool_input}\")\n",
    "        tool_output = call_tool(tool_name, tool_input)\n",
    "\n",
    "        tool_result_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_use_id,\n",
    "                    \"content\": [{\"json\": tool_output}]\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "\n",
    "        log(f\"[Tool Result] {tool_result_message}\")\n",
    "        messages.append(tool_result_message)\n",
    "\n",
    "        # Continue the conversation\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=\"us.amazon.nova-pro-v1:0\",\n",
    "            messages=messages,\n",
    "            toolConfig=tools\n",
    "        )\n",
    "        update_usage(response)\n",
    "\n",
    "    return response['output']['message']['content'][0]['text'], total_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_input = \"What is the most popular song on WZPZ?\"\n",
    "converse_with_tools(user_input, tool_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c6479-1a5c-4601-9023-665464e44c81",
   "metadata": {},
   "source": [
    "## Amazon Bedrock - Function Calling with LiteLLM\n",
    "\n",
    "Amazon Bedrock uses a different tool definition from the OpenAI Completion standard. Therefore, we have to change the definition before passing it to LiteLLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baaae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bedrock_tools_to_litellm_tools(bedrock_tools: dict)-> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert Bedrock tool configuration to a format compatible with Litellm.\n",
    "\n",
    "    Args:\n",
    "        bedrock_tools: Bedrock tool configuration dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing the tools in a format compatible with Litellm.\n",
    "    \"\"\"\n",
    "    litellm_tools = []\n",
    "    for tool in bedrock_tools['tools']:\n",
    "        litellm_tool = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool['toolSpec']['name'],\n",
    "                \"description\": tool['toolSpec']['description'],\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": tool['toolSpec']['inputSchema']['json']['properties'],\n",
    "                    \"required\": tool['toolSpec']['inputSchema']['json'].get('required', [])\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        litellm_tools.append(litellm_tool)\n",
    "    return litellm_tools\n",
    "\n",
    "def litellm_tools_to_bedrock_tools(litellm_tools: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Convert Litellm tool configuration to a format compatible with Bedrock.\n",
    "\n",
    "    Args:\n",
    "        litellm_tools: List of dictionaries representing the tools in a format compatible with Litellm.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the tools in a format compatible with Bedrock.\n",
    "    \"\"\"\n",
    "    bedrock_tools = {\n",
    "        \"tools\": []\n",
    "    }\n",
    "    for tool in litellm_tools:\n",
    "        bedrock_tool = {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": tool['function']['name'],\n",
    "                \"description\": tool['function']['description'],\n",
    "                \"inputSchema\": tool['function']['parameters']\n",
    "            }\n",
    "        }\n",
    "        bedrock_tools['tools'].append(bedrock_tool)\n",
    "    return bedrock_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3feb30-8f54-4224-9489-0cb1b6e3d069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import litellm\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {'role':'system', 'content':\"You are a helpful assistant.\"},\n",
    "    {'role':'user', 'content':input_text}\n",
    "]\n",
    "\n",
    "response = litellm.completion(\n",
    "    model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
    "    messages=messages,\n",
    "    tools=bedrock_tools_to_litellm_tools(tool_config),\n",
    ")\n",
    "messages.append(response['choices'][0]['message'])\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c010dc",
   "metadata": {},
   "source": [
    "With the complete function loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import litellm\n",
    "\n",
    "def converse_with_tools_litellm(\n",
    "    input_text: str,\n",
    "    tool_config: Dict[str, Any],\n",
    "    verbose: bool = False\n",
    ") -> Tuple[Dict[str, Any], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Converse using LiteLLM with Bedrock and tool support. Tracks token usage.\n",
    "\n",
    "    Args:\n",
    "        input_text: User query.\n",
    "        tool_config: Tool configuration for litellm.\n",
    "        verbose: Whether to log intermediate steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (final assistant message, token usage dictionary).\n",
    "    \"\"\"\n",
    "    def log(msg):\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def call_tool(name: str, args: str) -> Any:\n",
    "        try:\n",
    "            parsed_args = json.loads(args)\n",
    "            return getattr(sys.modules[__name__], name)(**parsed_args)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error calling tool '{name}': {e}\")\n",
    "\n",
    "    def extract_tokens(response: Dict[str, Any]) -> Dict[str, int]:\n",
    "        usage = response.get(\"usage\", {})\n",
    "        return {\n",
    "            \"inputTokens\": usage.get(\"prompt_tokens\", 0),\n",
    "            \"outputTokens\": usage.get(\"completion_tokens\", 0),\n",
    "            \"totalTokens\": usage.get(\"total_tokens\", 0)\n",
    "        }\n",
    "\n",
    "    messages: List[Dict[str, Any]] = [\n",
    "        {'role': 'system', 'content': \"You are a helpful assistant.\"},\n",
    "        {'role': 'user', 'content': input_text}\n",
    "    ]\n",
    "\n",
    "    # Initial call\n",
    "    response = litellm.completion(\n",
    "        model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
    "        messages=messages,\n",
    "        tools=tool_config,\n",
    "    )\n",
    "    usage_total = extract_tokens(response)\n",
    "    message = response['choices'][0]['message']\n",
    "    messages.append(message.__dict__)\n",
    "\n",
    "    # Process tool calls if any\n",
    "    if getattr(message, \"tool_calls\", None):\n",
    "        for tool_call in message.tool_calls:\n",
    "            log(f\"[Tool] Calling: {tool_call.function.name} with args {tool_call.function.arguments}\")\n",
    "            result = call_tool(tool_call.function.name, tool_call.function.arguments)\n",
    "            log(f\"[Tool] Result: {result}\")\n",
    "\n",
    "            tool_msg = {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_call.function.name,\n",
    "                \"content\": json.dumps(result),\n",
    "            }\n",
    "            messages.append(tool_msg)\n",
    "\n",
    "        # Follow-up model call with tool outputs\n",
    "        response = litellm.completion(\n",
    "            model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
    "            messages=messages,\n",
    "            tools=tool_config,\n",
    "        )\n",
    "        usage_followup = extract_tokens(response)\n",
    "        for k in usage_total:\n",
    "            usage_total[k] += usage_followup[k]\n",
    "\n",
    "        final_message = response['choices'][0]['message']\n",
    "        messages.append(final_message.__dict__)\n",
    "    else:\n",
    "        final_message = message\n",
    "\n",
    "    return final_message.content, usage_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab122e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_input = \"What is the most popular song on WZPZ?\"\n",
    "converse_with_tools_litellm(user_input, bedrock_tools_to_litellm_tools(tool_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e37a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
