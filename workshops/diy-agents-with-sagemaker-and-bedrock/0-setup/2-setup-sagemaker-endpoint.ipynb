{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586f2662-a568-4c29-af10-7bcb2eadbf30",
   "metadata": {},
   "source": [
    "# Deploying an LLM to Amazon SageMaker AI real-time endpoint\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To use SageMaker AI endpoints in these examples, you will need to first deploy a managed endpoint. In this example you will deploy an endpoint through SageMaker Jumpstart, a feature that helps machine learning practitioners quickly get started with hundreds of production-ready models in SageMaker AI.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Important:</b> Make sure you've run the <code>1-required-dependencies.ipynb</code> notebook in this folder before proceeding. If you haven't, close this notebook, run the previous one first, then come back to this.\n",
    "</div>\n",
    "\n",
    "## Deploy the model\n",
    "\n",
    "> Note: skip the cell below if you have already deployed your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.djl_inference import DJLModel\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except:\n",
    "    role = input(\"Enter your SageMaker role ARN: \")\n",
    "\n",
    "model_id = \"Qwen/Qwen3-4B\"\n",
    "model_name = name_from_base(model_id.split(\"/\")[1])\n",
    "endpoint_name = name_from_base(model_id.split(\"/\")[1]+\"-ep\")\n",
    "model = DJLModel(\n",
    "    name=model_name, role=role,\n",
    "    image_uri=f\"763104351884.dkr.ecr.{boto3.Session().region_name}.amazonaws.com/djl-inference:0.34.0-lmi16.0.0-cu128-v1.2\",\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": model_id,
    "        \"OPTION_MAX_MODEL_LEN\": f\"{1024*16}\",\n",
    "        \"OPTION_QUANTIZE\": \"fp8\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "        \"OPTION_DTYPE\": \"bf16\",\n",
    "        \"SERVING_FAIL_FAST\": \"true",\n",
    "        \"OPTION_ROLLING_BATCH\": \"disable",\n",
    "        \"OPTION_ASYNC_MODE\": \"true",\n",
    "        \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service",\n",
    "        \"OPTION_ENABLE_AUTO_TOOL_CHOICE\": \"true\",\n",
    "        \"OPTION_TOOL_CALL_PARSER\": \"hermes\",\n",
    "        \"OPTION_ENABLE_REASONING\": \"true\",\n",
    "        \"OPTION_REASONING_PARSER\": \"qwen3\"
    "    }\n",
    ")\n",
    "model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6de49-11f7-4e36-b7bb-322282a51e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAGEMAKER_ENDPOINT_NAME = model.endpoint_name\n",
    "print(f\"Endpoint name: {SAGEMAKER_ENDPOINT_NAME}\")\n",
    "\n",
    "%store SAGEMAKER_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12f8be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ <b>Note:</b> deployment will take 5~7 minutes. Take note of the endpoint name and the inference component names, as they will be needed later.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
