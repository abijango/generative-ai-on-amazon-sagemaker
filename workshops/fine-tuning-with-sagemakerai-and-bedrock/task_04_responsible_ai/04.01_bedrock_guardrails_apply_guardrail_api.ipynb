{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bfca55-c771-4e26-a13b-3451f6bef06a",
   "metadata": {},
   "source": [
    "# Applying Bedrock Guardrails to the Qwen3-4B-Instruct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41c9b6-e40e-4408-8209-faa9db60da8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "Guardrails can be used to implement safeguards for your generative AI applications that are customized to your use cases and aligned with your responsible AI policies. Guardrails allows you to:\n",
    "\n",
    "- Configure denied topics\n",
    "- Filter harmful content\n",
    "- Remove sensitive information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fa5fb-589a-4d83-8083-ba926f327b4e",
   "metadata": {},
   "source": [
    "## The`ApplyGuardrail` API allows you to assess any text using pre-configured Bedrock Guardrails, without invoking the foundation models.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "1. **Content Validation**: Send any text input or output to the ApplyGuardrail API to have it evaluated against your defined topic avoidance rules, content filters, PII detectors, and word blocklists. You can evaluate user inputs and FM generated outputs independently.\n",
    "\n",
    "2. **Flexible Deployment**: Integrate the Guardrails API anywhere in your application flow to validate data before processing or serving results to users. E.g. For a RAG application, you can now evaluate the user input prior to performing the retrieval instead of waiting until the final response generation.\n",
    "\n",
    "3. **Decoupled from Foundation Models**: ApplyGuardrail is decoupled from foundational models. You can now use Guardrails without invoking Foundation Models.\n",
    "\n",
    "You can use the assessment results to design the experience on your generative AI application. Let's now walk through a code-sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4bb6c-9a91-4d44-9457-551293c20dd1",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd569723-3c66-4569-82a0-a2538eb73921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9b13f-899e-4775-8329-27372b94b6b6",
   "metadata": {},
   "source": [
    "## This cell will restart the kernel. Click \"OK\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c60726-0f0a-4d09-8d4f-4923f015f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db97c3-07e5-4219-9b78-6a60728437f2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa341fb6-dce9-4b79-a070-a98020870221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from typing import Dict, Any\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bedrock_client = boto3.client('bedrock', region_name=sess.boto_region_name)\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=sess.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ced34f-91e4-4093-8b3e-1ce7a6600188",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r TUNED_ENDPOINT_NAME\n",
    "\n",
    "# set the endpoint name manually by uncommenting below\n",
    "#TUNED_ENDPOINT_NAME = \"\"  # Update with Fine-tuned model endpoint name\n",
    "\n",
    "print(f\"Tuned Endpoint: {TUNED_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3480e72-04ac-4caf-86bd-0fae2cb8fcc1",
   "metadata": {},
   "source": [
    "## Create a guardrail\n",
    "\n",
    "Before running the code to apply a guardrail, you need to create a guardrail in Amazon Bedrock. We will create a guardrail that blocks input prompts and output responses from the model providing medical advice and obfuscates PII data, in addition to blocking generally harmful content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d82166-6725-4dab-96fa-f0ab2b1a0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique client request token\n",
    "client_request_token = str(uuid.uuid4())\n",
    "\n",
    "# Create a Guardrail with specific filtering and compliance policies for medical use-case\n",
    "response = bedrock_client.create_guardrail(\n",
    "    name=\"MedicalContextGuardrails\",\n",
    "    description=\"Restrict responses to verified medical content only\",\n",
    "    blockedInputMessaging=\"Input Blocked: Sorry, I cannot provide non-medical advice, confirm/deny unverified medical information, or make any claims of guaranteed/definitive cures without sufficient evidence.\",\n",
    "    blockedOutputsMessaging=\"Output Blocked: Sorry, I cannot provide non-medical advice, confirm/deny unverified medical information, or make any claims of guaranteed/definitive cures without sufficient evidence.\",\n",
    "\n",
    "    # Topic-based restrictions (e.g., denying non-medical advice)\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {'name': 'non-medical-advice', 'definition': 'Any recommendations outside medical expertise or context', 'type': 'DENY'},\n",
    "            {'name': 'misinformation', 'definition': 'Dissemination of inaccurate or unverified medical information', 'type': 'DENY'},\n",
    "            {'name': 'medical-cure-claims', 'definition': 'Claims of guaranteed or definitive cures for medical conditions without sufficient evidence', 'type': 'DENY'}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Content filtering policies (e.g., blocking harmful or unethical content)\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {'type': 'HATE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'INSULTS', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'SEXUAL', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'VIOLENCE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'MISCONDUCT', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'PROMPT_ATTACK', 'inputStrength': 'HIGH', 'outputStrength': 'NONE'}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # List of restricted words related to sensitive medical topics\n",
    "    wordPolicyConfig={\n",
    "        # Example: blocking inappropriate usage of critical medical terms\n",
    "        'wordsConfig': [\n",
    "            {'text': \"malpractice\"}, {'text': \"misdiagnosis\"}, {'text': \"unauthorized treatment\"},\n",
    "            {'text': \"experimental drug\"}, {'text': \"unapproved therapy\"}, {'text': \"medical fraud\"},\n",
    "            {'text': \"cure\"}, {'text': \"guaranteed cure\"}, {'text': \"permanent remission\"}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Sensitive data anonymization (e.g., patient information)\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        # Anonymize identifiable patient information\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': \"NAME\", \"action\": \"ANONYMIZE\"}, {'type': \"EMAIL\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"PHONE\", \"action\": \"ANONYMIZE\"}, {'type': \"US_SOCIAL_SECURITY_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"ADDRESS\", \"action\": \"ANONYMIZE\"}, {'type': \"CA_HEALTH_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"PASSWORD\", \"action\": \"ANONYMIZE\"}, {'type': \"IP_ADDRESS\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"CA_SOCIAL_INSURANCE_NUMBER\", \"action\": \"ANONYMIZE\"}, {'type': \"CREDIT_DEBIT_CARD_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"AGE\", \"action\": \"ANONYMIZE\"}, {'type': \"US_BANK_ACCOUNT_NUMBER\", \"action\": \"ANONYMIZE\"}\n",
    "        ],\n",
    "        # Example regex patterns for anonymizing sensitive medical data\n",
    "        'regexesConfig': [\n",
    "            {\n",
    "                \"name\": \"medical_procedure_code\",\n",
    "                \"description\": \"Pattern for medical procedure codes\",\n",
    "                \"pattern\": \"\\\\b[A-Z]{1,5}\\\\d{1,5}\\\\b\",\n",
    "                \"action\": \"ANONYMIZE\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"clinical_trial_id\",\n",
    "                \"description\": \"Pattern for clinical trial identifiers\",\n",
    "                \"pattern\": \"\\\\bNCT\\\\d{8}\\\\b\",\n",
    "                \"action\": \"ANONYMIZE\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Tags for environment tracking\n",
    "    tags=[\n",
    "        {\"key\": \"Environment\", \"value\": \"Production\"},\n",
    "        {\"key\": \"Department\", \"value\": \"Medical\"}\n",
    "    ],\n",
    "    clientRequestToken=client_request_token,\n",
    ")\n",
    "\n",
    "# Retrieve and print the Guardrail ID, ARN, and version\n",
    "guardrail_id = response['guardrailId']\n",
    "\n",
    "print(f\"Guardrail ID: {guardrail_id}\")\n",
    "print(f\"Guardrail ARN: {response['guardrailArn']}\")\n",
    "print(f\"Version: {response['version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ac0bd-fe95-4d52-9261-70ca1bf13cdf",
   "metadata": {},
   "source": [
    "Next, publish the draft of the guardrail so it can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a845db-851d-405d-b6f5-819a214ffa52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# First create a published version\n",
    "version_response = bedrock_client.create_guardrail_version(\n",
    "    guardrailIdentifier=response['guardrailId'],\n",
    "    description=\"Production version 1.0\"\n",
    ")\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "guardrail_version = version_response['version']\n",
    "\n",
    "print(f\"Guardrail published with version: {guardrail_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8e9d9-8036-4683-afcc-1d27ec240d57",
   "metadata": {},
   "source": [
    "With a guardrail in place, you can now test its effectiveness. When processing input queries, no model is required and the `apply_guardrail` API can be invoked on the incoming request alone. The API will reply with an `action` field, showing whether the guardrail interviened which can be used to determine whether to send requests to the downstream LLM or to take some other action.\n",
    "\n",
    "### Example: Blocking Medical Advice\n",
    "In this example, the input prompt requests guidance on cures for COVID-19. Since the guardrail being invoked is configured to flag anything asking for medical advice or non-verified medical content, this request is blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98f4b1-129f-4c1a-8ce9-15482a52c52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of Input Prompt being Analyzed\n",
    "content = [\n",
    "    {\n",
    "        \"text\": {\n",
    "            \"text\": \"Are there any cures for COVID-19?\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the ApplyGuardrail API\n",
    "try:\n",
    "    response = bedrock_runtime.apply_guardrail(\n",
    "        guardrailIdentifier=guardrail_id,\n",
    "        guardrailVersion=guardrail_version,\n",
    "        source='INPUT',  # or 'INPUT' depending on your use case\n",
    "        content=content\n",
    "    )\n",
    "    \n",
    "    # Process the response\n",
    "    #print(\"API Response:\")\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    \n",
    "    # Check the action taken by the guardrail\n",
    "    if response['action'] == 'GUARDRAIL_INTERVENED':\n",
    "        print(\"\\nGuardrail intervened. \\n\\nOutput:\")\n",
    "        for output in response['outputs']:\n",
    "            print(output['text'])\n",
    "    else:\n",
    "        print(\"\\nGuardrail did not intervene.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    print(\"\\nAPI Response (if available):\")\n",
    "    try:\n",
    "        print(json.dumps(response, indent=2))\n",
    "    except NameError:\n",
    "        print(\"No response available due to early exception.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b944fb-0402-469d-b0c8-67afda4de22e",
   "metadata": {},
   "source": [
    "### Example: Anonymization of PII in responses.\n",
    "\n",
    "The guardrail in this example is configured to look at a variety of PII related field and anonymize them:\n",
    "- NAME\n",
    "- EMAIL\n",
    "- PHONE\n",
    "- US_SOCIAL_SECURITY_NUMBER\n",
    "- ADDRESS\n",
    "- CA_HEALTH_NUMBER\n",
    "- PASSWORD\n",
    "- IP_ADDRESS\n",
    "- CA_SOCIAL_INSURANCE_NUMBER\n",
    "- CREDIT_DEBIT_CARD_NUMBER\n",
    "- AGE\n",
    "- US_BANK_ACCOUNT_NUMBER\n",
    "\n",
    "In the input content there are 3 entries:\n",
    "- grounding source: ground truth context for the model to base its response on (simulated here)\n",
    "- query: the user input query\n",
    "- guard_content: the model output (simulated here)\n",
    "\n",
    "This guardrail is going to be applied on the model **output** in this example, which means it won't affect the inputs at all.\n",
    "\n",
    "A full list of all available types is available in the [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189e5ab-4a38-417e-b766-e84efbea17b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An Example of Analyzing an Output Response, This time using Contexual Grounding\n",
    "\n",
    "content = [\n",
    "    {\n",
    "        \"text\": {\n",
    "            \"text\": \"Clinical Trial NCT12345678 was performed by Dr. Vivek Murthy of Gainesville, Florida in 2022. Throughout a series of double-blind trials he was able to show the effects of catnip improving the cognitive functions of senior cats by 20%, but only for a few minutes.\",\n",
    "            \"qualifiers\": [\"grounding_source\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"text\": {\n",
    "            \"text\": \"Can you provide the contact information, including the phone number and email address, for Dr. Vivek Murthy, who led the clinical trial NCT12345678?\",\n",
    "            \"qualifiers\": [\"query\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"text\": {\n",
    "            \"text\": \"Dr. Vivek Murthy is based in Gainesville, Florida.\",\n",
    "            \"qualifiers\": [\"guard_content\"],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "# Call the ApplyGuardrail API\n",
    "try:\n",
    "    response = bedrock_runtime.apply_guardrail(\n",
    "        guardrailIdentifier=guardrail_id,\n",
    "        guardrailVersion=guardrail_version,\n",
    "        source='OUTPUT',  # or 'INPUT' depending on your use case\n",
    "        content=content\n",
    "    )\n",
    "    \n",
    "    # Process the response\n",
    "    #print(\"API Response:\")\n",
    "    #print(json.dumps(response, indent=2))\n",
    "    \n",
    "    # Check the action taken by the guardrail\n",
    "    if response['action'] == 'GUARDRAIL_INTERVENED':\n",
    "        print(\"\\nGuardrail intervened. \\n\\nOutput:\")\n",
    "        for output in response['outputs']:\n",
    "            print(output['text'])\n",
    "    else:\n",
    "        print(\"\\nGuardrail did not intervene.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    print(\"\\nAPI Response (if available):\")\n",
    "    try:\n",
    "        print(json.dumps(response, indent=2))\n",
    "    except NameError:\n",
    "        print(\"No response available due to early exception.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225dd51-c1a3-4621-a902-f9700d8ac6b4",
   "metadata": {},
   "source": [
    "## Using ApplyGuardrail API with a Third-Party or Self-Hosted Model\n",
    "\n",
    "A common use case for the ApplyGuardrail API is in conjunction with a Language Model from a non Amazon Bedrock provider, or a model that you self-host. This combination allows you to apply guardrails to the input or output of any request.\n",
    "\n",
    "The general flow would be:\n",
    "1. Receive an input for your Model\n",
    "2. Apply the guardrail to this input using the ApplyGuardrail API\n",
    "3. If the input passes the guardrail, send it to your Model for Inference\n",
    "4. Receive the output from your Model\n",
    "5. Apply the Guardrail to your output\n",
    "6. Return the final (potentially modified) output\n",
    "\n",
    "### Here's a diagram illustrating this process:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/applyguardrail.png\" alt=\"ApplyGuardrail API Flow\" style=\"max-width: 100%;\">\n",
    "</div>\n",
    "\n",
    "Let's walk through this with a code example that demonstrates this process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f2797-24ec-4361-bd09-20d31efb5509",
   "metadata": {},
   "source": [
    "### These examples use SageMaker hosted model endpoint, but this could be any third-party model as well\n",
    "\n",
    "We will use the `Qwen3-4B-Instruct-2507` model that we deployed earlier on a SageMaker Endpoint. \n",
    "\n",
    "### Incorporating the ApplyGuardrail API into our Self-Hosted Model\n",
    "\n",
    "---\n",
    "We've created a `TextGenerationWithGuardrails` class that integrates the ApplyGuardrail API with our SageMaker endpoint to ensure protected text generation. This class includes the following key methods:\n",
    "\n",
    "1. `generate_text`: Calls our Language Model via a SageMaker endpoint to generate text based on the input.\n",
    "\n",
    "2. `analyze_text`: A core method that applies our guardrail using the ApplyGuardrail API. It int|erprets the API response to determine if the guardrail passed or intervened.\n",
    "\n",
    "3. `analyze_prompt` and `analyze_output`: These methods use `analyze_text` to apply our guardrail to the input prompt and generated output, respectively. They return a tuple indicating whether the guardrail passed and any associated message.\n",
    "\n",
    "The class looks to implement the diagram above. It works as follows:\n",
    "\n",
    "1. It first checks the input prompt using `analyze_prompt`.\n",
    "2. If the input passes the guardrail, it generates text using `generate_text`.\n",
    "3. The generated text is then checked using `analyze_output`.\n",
    "4. If both guardrails pass, the generated text is returned. Otherwise, an intervention message is provided.\n",
    "\n",
    "This structure allows for comprehensive safety checks both before and after text generation, with clear handling of cases where guardrails intervene. It's designed to easily integrate with larger applications while providing flexibility for error handling and customization based on guardrail results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96fdd1-8eff-4351-8063-4bd8e5883c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "from typing import Tuple, List, Dict, Any\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "class TextGenerationWithGuardrails:\n",
    "    def __init__(self, endpoint_name: str, guardrail_id: str, guardrail_version: str, sagemaker_session=None):\n",
    "        \"\"\"\n",
    "        Initialize the text generation class with guardrails.\n",
    "        \n",
    "        Args:\n",
    "            endpoint_name: The SageMaker endpoint name\n",
    "            model_id: The model ID (optional but useful for documentation)\n",
    "            guardrail_id: The AWS Bedrock guardrail ID\n",
    "            guardrail_version: The AWS Bedrock guardrail version\n",
    "            sagemaker_session: SageMaker session object\n",
    "        \"\"\"\n",
    "        # Create predictor directly instead of using retrieve_default\n",
    "        self.predictor = Predictor(\n",
    "            endpoint_name=endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=JSONSerializer(),\n",
    "            deserializer=JSONDeserializer()\n",
    "        )\n",
    "        self.bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "        self.guardrail_id = guardrail_id\n",
    "        self.guardrail_version = guardrail_version\n",
    "\n",
    "    def generate_text(self, inputs: str, max_new_tokens: int = 256, temperature: float = 0.0) -> str:\n",
    "        \"\"\"Generate text using the specified SageMaker endpoint.\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": inputs}]\n",
    "        \n",
    "        payload = {\n",
    "            \"messages\": messages,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": max_new_tokens,\n",
    "                \"temperature\": temperature,\n",
    "                \"stop\": \"<|eot_id|>\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        response = self.predictor.predict(payload)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    def analyze_text(self, grounding_source: str, query: str, guard_content: str, source: str) -> Tuple[bool, str, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Analyze text using the ApplyGuardrail API with contextual grounding.\n",
    "        Returns a tuple (passed, message, details) where:\n",
    "        - passed is a boolean indicating if the guardrail passed,\n",
    "        - message is either the guardrail message or an empty string,\n",
    "        - details is a dictionary containing the full API response for further analysis if needed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = [\n",
    "                {\n",
    "                    \"text\": {\n",
    "                        \"text\": grounding_source,\n",
    "                        \"qualifiers\": [\"grounding_source\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"text\": {\n",
    "                        \"text\": query,\n",
    "                        \"qualifiers\": [\"query\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"text\": {\n",
    "                        \"text\": guard_content,\n",
    "                        \"qualifiers\": [\"guard_content\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            response = self.bedrock_runtime.apply_guardrail(\n",
    "                guardrailIdentifier=self.guardrail_id,\n",
    "                guardrailVersion=self.guardrail_version,\n",
    "                source=source,\n",
    "                content=content\n",
    "            )\n",
    "            \n",
    "            action = response.get(\"action\", \"\")\n",
    "            if action == \"NONE\":\n",
    "                return True, \"\", response\n",
    "            elif action == \"GUARDRAIL_INTERVENED\":\n",
    "                message = response.get(\"outputs\", [{}])[-1].get(\"text\", \"Guardrail intervened\")\n",
    "                return False, message, response\n",
    "            else:\n",
    "                return False, f\"Unknown action: {action}\", response\n",
    "        except ClientError as e:\n",
    "            print(f\"Error applying guardrail: {e}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_prompt(self, grounding_source: str, query: str) -> Tuple[bool, str, Dict[str, Any]]:\n",
    "        \"\"\"Analyze the input prompt.\"\"\"\n",
    "        return self.analyze_text(grounding_source, query, query, \"INPUT\")\n",
    "\n",
    "    def analyze_output(self, grounding_source: str, query: str, generated_text: str) -> Tuple[bool, str, Dict[str, Any]]:\n",
    "        \"\"\"Analyze the generated output.\"\"\"\n",
    "        return self.analyze_text(grounding_source, query, generated_text, \"OUTPUT\")\n",
    "\n",
    "    def generate_and_analyze(self, grounding_source: str, query: str, max_new_tokens: int = 256, temperature: float = 0.0) -> Tuple[bool, str, str]:\n",
    "        \"\"\"\n",
    "        Generate text and analyze it with guardrails.\n",
    "        Returns a tuple (passed, message, generated_text) where:\n",
    "        - passed is a boolean indicating if the guardrail passed,\n",
    "        - message is either the guardrail message or an empty string,\n",
    "        - generated_text is the text generated by the model (if guardrail passed) or an empty string.\n",
    "        \"\"\"\n",
    "        # First, analyze the prompt\n",
    "        prompt_passed, prompt_message, _ = self.analyze_prompt(grounding_source, query)\n",
    "        if not prompt_passed:\n",
    "            return False, prompt_message, \"\"\n",
    "\n",
    "        # If prompt passes, generate text\n",
    "        generated_text = self.generate_text(query, max_new_tokens, temperature)\n",
    "\n",
    "        # Analyze the generated text\n",
    "        output_passed, output_message, _ = self.analyze_output(grounding_source, query, generated_text)\n",
    "        if not output_passed:\n",
    "            return False, output_message, \"\"\n",
    "\n",
    "        return True, \"\", generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ac6a0-293b-4ea4-b314-0aead2a5af75",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "The following examples will allow you to test guardrail functionalize with your SageMaker hosted FM. \n",
    "\n",
    "The `test_generation_with_guardrail` function defined below will take a `TextGenerationWithGuardrails` along with model inputs, process the inputs with the supplied guardrail, send the inputs to your FM (if it passes), then process the model outputs with the guardrail before returning a final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81517bf-45a3-495a-a5f6-eee5f94e0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bold text function\n",
    "def bold(text):\n",
    "    return f\"\\033[1m{text}\\033[0m\"\n",
    "\n",
    "def test_generation_with_guardrail(text_gen: TextGenerationWithGuardrails, query, grounding_source=\"\", max_new_tokens=512, temperature=0.0, print_api_responses=False):\n",
    "    # Analyze input\n",
    "    print(bold(\"\\n=== Input Analysis ===\\n\"))\n",
    "    input_passed, input_message, input_details = text_gen.analyze_prompt(grounding_source, query)\n",
    "    if not input_passed:\n",
    "        print(f\"Input Guardrail Intervened. \\n\\nThe response to the User is: \\n\\n{input_message}\\n\")\n",
    "        if print_api_responses:\n",
    "            print(\"Full API Response:\")\n",
    "            print(json.dumps(input_details, indent=2))\n",
    "        print()\n",
    "    else:\n",
    "        print(\"Input Prompt Passed The Guardrail Check - Moving to Generate the Response\\n\")\n",
    "    \n",
    "        # Generate text\n",
    "        print(bold(\"\\n=== Text Generation ===\\n\"))\n",
    "        generated_text = text_gen.generate_text(query, max_new_tokens=max_new_tokens, temperature=temperature)\n",
    "        print(f\"Here is what the Model Responded with: \\n\\n{generated_text}\\n\")\n",
    "        \n",
    "        # Analyze output\n",
    "        print(bold(\"\\n=== Output Analysis ===\\n\"))\n",
    "        print(\"Analyzing Model Response with the Response Guardrail\\n\")\n",
    "        output_passed, output_message, output_details = text_gen.analyze_output(grounding_source, query, generated_text)\n",
    "        if not output_passed:\n",
    "            print(f\"Output Guardrail Intervened. \\n\\nThe response to the User is: \\n\\n{output_message}\\n\")\n",
    "            if print_api_responses:\n",
    "                print(\"Full API Response:\")\n",
    "                print(json.dumps(output_details[\"outputs\"], indent=2))\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"Model Response Passed. The information presented to the user is: \\n\\n{generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be81f8c-932f-4ab7-883c-009820c98e9c",
   "metadata": {},
   "source": [
    "Initialize the `TextGenerationWithGuardrails` class with the SageMaker endpoint and Guardrail, then test with a variety of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a0c10-45ac-4353-a04a-dc05c4602577",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = TextGenerationWithGuardrails(\n",
    "    endpoint_name=TUNED_ENDPOINT_NAME,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf7135-51c5-48b9-b1cb-69611cdb46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generation_with_guardrail(\n",
    "    text_gen,\n",
    "    query=\"Is there a cure for COVID-19?\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0056b5a-2d18-4421-bd9c-8bf3859bbd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generation_with_guardrail(\n",
    "    text_gen,\n",
    "    query=\"Can you provide the contact information, including the phone number and email address, for Dr. Vivek Murthy, who led the clinical trial NCT12345678?\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb4f3b-ce07-4706-a1af-680197dd3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generation_with_guardrail(\n",
    "    text_gen,\n",
    "    query=\"Given the symptoms of sudden weakness in the left arm and leg, recent long-distance travel, and the presence of swollen and tender right lower leg, what specific cardiac abnormality is most likely to be found upon further evaluation that could explain these findings?\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719d546-87a2-4f34-8f6f-ae0b5002625f",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully implemented a guardrail for your model to help protect the inputs and outputs of your application. Continue to the clean up section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f33392-61ab-4fc5-9279-a62fbdc62a12",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61498705-28fa-485d-9371-244c9353b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client.delete_guardrail(guardrailIdentifier=guardrail_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b94020-3181-41eb-aab7-fd03628af406",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "delete_sft_response = sagemaker_client.delete_endpoint(\n",
    "    EndpointName=TUNED_ENDPOINT_NAME\n",
    ")\n",
    "\n",
    "print(delete_sft_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93a3ed-8bc6-4c31-81cf-9876ca33fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_sftcfg_response = sagemaker_client.delete_endpoint_config(\n",
    "    EndpointConfigName=TUNED_ENDPOINT_NAME\n",
    ")\n",
    "print(delete_sftcfg_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2483ba6-8ef8-4307-a4ef-002e64ee7d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
