{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Fine-tune LLM with PyTorch FSDP and QLora on Amazon SageMaker AI using ModelTrainer\n",
    "\n",
    "In this notebook, we will fine-tune LLM on Amazon SageMaker AI, using Python scripts and SageMaker ModelTrainer for executing a training job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca016c-d4fa-4213-a7b3-03b449551449",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907944ea-dbfb-4de0-9e13-1fd28c901031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:18.011025Z",
     "iopub.status.busy": "2025-05-15T05:05:18.010839Z",
     "iopub.status.idle": "2025-05-15T05:05:21.434628Z",
     "shell.execute_reply": "2025-05-15T05:05:21.434035Z",
     "shell.execute_reply.started": "2025-05-15T05:05:18.011008Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e40af5-9e47-4023-ae7e-e01c76c32440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:21.435577Z",
     "iopub.status.busy": "2025-05-15T05:05:21.435341Z",
     "iopub.status.idle": "2025-05-15T05:05:21.439284Z",
     "shell.execute_reply": "2025-05-15T05:05:21.438830Z",
     "shell.execute_reply.started": "2025-05-15T05:05:21.435555Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c9e5c-c57c-42cd-baf4-e139422cc147",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "## Setup Configuration file path\n",
    "\n",
    "If you have created a Managed MLflow server, copy the `ARN` code here and assign a name to the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51663-0171-4d54-b16e-f85e3cadb692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:21.444359Z",
     "iopub.status.busy": "2025-05-15T05:05:21.444163Z",
     "iopub.status.idle": "2025-05-15T05:05:21.447264Z",
     "shell.execute_reply": "2025-05-15T05:05:21.446773Z",
     "shell.execute_reply.started": "2025-05-15T05:05:21.444342Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"mlflow_uri\"] = \"\"\n",
    "os.environ[\"mlflow_experiment_name\"] = \"deepseek-r1-distill-llama-8b-sft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b95b61-8666-4015-bf2e-fcf68ce38c5b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82089d28-b97a-4956-83fb-d8c46d44fdb5",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "We are going to load [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc5fa8-51b5-419c-9a87-784022e23e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:55.572481Z",
     "start_time": "2023-11-15T09:24:52.575954Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:21.452105Z",
     "iopub.status.busy": "2025-05-15T05:05:21.451948Z",
     "iopub.status.idle": "2025-05-15T05:05:23.251932Z",
     "shell.execute_reply": "2025-05-15T05:05:23.251383Z",
     "shell.execute_reply.started": "2025-05-15T05:05:21.452090Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d973b5e-ac00-4b10-8425-5c4ca4b31f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:23.252819Z",
     "iopub.status.busy": "2025-05-15T05:05:23.252618Z",
     "iopub.status.idle": "2025-05-15T05:05:23.815268Z",
     "shell.execute_reply": "2025-05-15T05:05:23.814717Z",
     "shell.execute_reply.started": "2025-05-15T05:05:23.252802Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481791d-9c86-4d32-a39a-918aff5e432f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:23.816177Z",
     "iopub.status.busy": "2025-05-15T05:05:23.815915Z",
     "iopub.status.idle": "2025-05-15T05:05:25.224377Z",
     "shell.execute_reply": "2025-05-15T05:05:25.223733Z",
     "shell.execute_reply.started": "2025-05-15T05:05:23.816159Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\")\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df = df[:1000]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69e7cf-1b66-4246-90d4-b855a2f8bd3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:25.225554Z",
     "iopub.status.busy": "2025-05-15T05:05:25.225068Z",
     "iopub.status.idle": "2025-05-15T05:05:25.561999Z",
     "shell.execute_reply": "2025-05-15T05:05:25.561404Z",
     "shell.execute_reply.started": "2025-05-15T05:05:25.225530Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"Number of train elements: \", len(train))\n",
    "print(\"Number of test elements: \", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368c020-e9a3-48b3-a53b-45404bba9482",
   "metadata": {},
   "source": [
    "Create a prompt template and load the dataset with a random sample to try summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb8edd-35c0-4cf1-82d3-54417bdabd6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:01.435195Z",
     "start_time": "2023-09-03T00:02:01.429794Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:25.568248Z",
     "iopub.status.busy": "2025-05-15T05:05:25.568004Z",
     "iopub.status.idle": "2025-05-15T05:05:25.571894Z",
     "shell.execute_reply": "2025-05-15T05:05:25.571427Z",
     "shell.execute_reply.started": "2025-05-15T05:05:25.568228Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom instruct prompt start\n",
    "prompt_template = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{{question}}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{{complex_cot}}\n",
    "\n",
    "{{answer}}\n",
    "<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = prompt_template.format(question=sample[\"Question\"],\n",
    "                                            complex_cot=sample[\"Complex_CoT\"],\n",
    "                                            answer=sample[\"Response\"])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0a32-96c2-4285-b593-3de211f79933",
   "metadata": {},
   "source": [
    "Use the Hugging Face Trainer class to fine-tune the model. Define the hyperparameters we want to use. We also create a DataCollator that will take care of padding our inputs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cbedd-7403-467e-8cc6-1d2550d8b8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:10.364459Z",
     "start_time": "2023-09-03T00:02:09.672705Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:25.575916Z",
     "iopub.status.busy": "2025-05-15T05:05:25.575750Z",
     "iopub.status.idle": "2025-05-15T05:05:25.734743Z",
     "shell.execute_reply": "2025-05-15T05:05:25.734200Z",
     "shell.execute_reply.started": "2025-05-15T05:05:25.575900Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from random import randint\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(template_dataset, remove_columns=list(dataset[\"train\"].features))\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(template_dataset, remove_columns=list(dataset[\"test\"].features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e667af-8197-4d2f-8432-82db6a1d3006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:46:36.592759Z",
     "iopub.status.busy": "2024-12-17T16:46:36.591798Z",
     "iopub.status.idle": "2024-12-17T16:46:36.603128Z",
     "shell.execute_reply": "2024-12-17T16:46:36.598965Z",
     "shell.execute_reply.started": "2024-12-17T16:46:36.592728Z"
    }
   },
   "source": [
    "### Upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f29e5-4aed-4939-8d51-ad3c5268299f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:25.738944Z",
     "iopub.status.busy": "2025-05-15T05:05:25.738771Z",
     "iopub.status.idle": "2025-05-15T05:05:25.741631Z",
     "shell.execute_reply": "2025-05-15T05:05:25.741147Z",
     "shell.execute_reply.started": "2025-05-15T05:05:25.738928Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db05863-3acb-483b-8e34-2aacbdbc68a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:25.742423Z",
     "iopub.status.busy": "2025-05-15T05:05:25.742207Z",
     "iopub.status.idle": "2025-05-15T05:05:26.622564Z",
     "shell.execute_reply": "2025-05-15T05:05:26.622029Z",
     "shell.execute_reply.started": "2025-05-15T05:05:25.742403Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d0321-1bd5-4c62-845a-bb1b9a3891a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:26.623679Z",
     "iopub.status.busy": "2025-05-15T05:05:26.623340Z",
     "iopub.status.idle": "2025-05-15T05:05:26.974093Z",
     "shell.execute_reply": "2025-05-15T05:05:26.973480Z",
     "shell.execute_reply.started": "2025-05-15T05:05:26.623650Z"
    }
   },
   "outputs": [],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f'{default_prefix}/datasets/llm-fine-tuning-modeltrainer-sft'\n",
    "else:\n",
    "    input_path = f'datasets/llm-fine-tuning-modeltrainer-sft'\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "train_dataset.to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "test_dataset.to_json(\"./data/test/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "s3_client.upload_file(\"./data/test/dataset.json\", bucket_name, f\"{input_path}/test/dataset.json\")\n",
    "test_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/test/dataset.json\"\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(test_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59858b-e895-4877-8c96-264e152c25cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:26.974980Z",
     "iopub.status.busy": "2025-05-15T05:05:26.974743Z",
     "iopub.status.idle": "2025-05-15T05:05:27.302361Z",
     "shell.execute_reply": "2025-05-15T05:05:27.301808Z",
     "shell.execute_reply.started": "2025-05-15T05:05:26.974964Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_validation_dataset):\n",
    "    lengths1 = [len(x[\"text\"].split()) for x in tokenized_train_dataset]\n",
    "    lengths2 = [len(x[\"text\"].split()) for x in tokenized_validation_dataset]\n",
    "    lengths = lengths1 + lengths2\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color=\"blue\")\n",
    "    plt.xlabel(\"prompt lengths\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of lengths of input_ids\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb0f5d-85df-4c18-a3a7-a62ecb010c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:27.303450Z",
     "iopub.status.busy": "2025-05-15T05:05:27.303035Z",
     "iopub.status.idle": "2025-05-15T05:05:27.533478Z",
     "shell.execute_reply": "2025-05-15T05:05:27.532889Z",
     "shell.execute_reply.started": "2025-05-15T05:05:27.303431Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data_lengths(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9c237-28bd-474e-9444-94aaea8e6979",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457beda-117d-4782-9f04-0680c199e98a",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5a09e-97de-4935-82c5-b56445e057fd",
   "metadata": {},
   "source": [
    "We are now ready to fine-tune our model. We will use the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) from transfomers to fine-tune our model. We prepared a script [train.py](./scripts/train.py) which will loads the dataset from disk, prepare the model, tokenizer and start the training.\n",
    "\n",
    "For configuration we use `TrlParser`, that allows us to provide hyperparameters in a `yaml` file. This yaml will be uploaded and provided to Amazon SageMaker similar to our datasets. Below is the config file for fine-tuning the model on `ml.g5.12xlarge`. We are saving the config file as `args.yaml` and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5aaaf-7d2f-4aae-87af-1b9e6b11b54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:27.543496Z",
     "iopub.status.busy": "2025-05-15T05:05:27.543281Z",
     "iopub.status.idle": "2025-05-15T05:05:27.552998Z",
     "shell.execute_reply": "2025-05-15T05:05:27.552404Z",
     "shell.execute_reply.started": "2025-05-15T05:05:27.543479Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./args.yaml <<EOF\n",
    "model_id: \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"       # Hugging Face model id\n",
    "mlflow_uri: \"${mlflow_uri}\"\n",
    "mlflow_experiment_name: \"${mlflow_experiment_name}\"\n",
    "# sagemaker specific parameters\n",
    "output_dir: \"/opt/ml/model\"                       # path to where SageMaker will upload the model \n",
    "train_dataset_path: \"/opt/ml/input/data/train/\"   # path to where FSx saves train dataset\n",
    "test_dataset_path: \"/opt/ml/input/data/test/\"     # path to where FSx saves test dataset\n",
    "# training parameters\n",
    "max_seq_length: 1500  #512 # 2048\n",
    "lora_r: 8\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.1                 \n",
    "learning_rate: 2e-4                    # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "gradient_checkpointing: true           # use gradient checkpointing\n",
    "fp16: true\n",
    "bf16: false                            # use bfloat16 precision, also enables FlashAttention2 (requires Ampere/Hopper GPU+ ex:A10, A100, H100)\n",
    "tf32: false                            # use tf32 precision\n",
    "fsdp: \"full_shard auto_wrap offload\"\n",
    "fsdp_config: \n",
    "    backward_prefetch: \"backward_pre\"\n",
    "    cpu_ram_efficient_loading: true\n",
    "    offload_params: true\n",
    "    forward_prefetch: false\n",
    "    use_orig_params: true\n",
    "merge_weights: true                    # merge weights in the base model\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd27c7-d367-43b1-8b61-ce15e0e262c1",
   "metadata": {},
   "source": [
    "Lets upload the config file to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70937e95-114e-40e1-b26a-49cc1cbd803b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:27.557339Z",
     "iopub.status.busy": "2025-05-15T05:05:27.557169Z",
     "iopub.status.idle": "2025-05-15T05:05:27.703830Z",
     "shell.execute_reply": "2025-05-15T05:05:27.703309Z",
     "shell.execute_reply.started": "2025-05-15T05:05:27.557323Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "if default_prefix:\n",
    "    input_path = f\"s3://{bucket_name}/{default_prefix}/datasets/llm-fine-tuning-modeltrainer-sft\"\n",
    "else:\n",
    "    input_path = f\"s3://{bucket_name}/datasets/llm-fine-tuning-modeltrainer-sft\"\n",
    "\n",
    "# upload the model yaml file to s3\n",
    "model_yaml = \"args.yaml\"\n",
    "train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\")\n",
    "\n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329683c-6662-45d3-b864-9cb575f92599",
   "metadata": {},
   "source": [
    "## Fine-tune model\n",
    "\n",
    "Below estimtor will train the model with QLoRA, merge the adapter in the base model and save in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178118a-0f45-4e5f-9bb1-7e5dee146b62",
   "metadata": {},
   "source": [
    "#### Get PyTorch image_uri\n",
    "\n",
    "We are going to use the native PyTorch container image, pre-built for Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5a03c-7660-4729-bf98-67ecb8ffa508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:27.711178Z",
     "iopub.status.busy": "2025-05-15T05:05:27.711012Z",
     "iopub.status.idle": "2025-05-15T05:05:27.714003Z",
     "shell.execute_reply": "2025-05-15T05:05:27.713523Z",
     "shell.execute_reply.started": "2025-05-15T05:05:27.711161Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.config import load_sagemaker_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaf81c-e8fb-4e42-a90d-50c2c55047bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:27.714715Z",
     "iopub.status.busy": "2025-05-15T05:05:27.714521Z",
     "iopub.status.idle": "2025-05-15T05:05:28.221828Z",
     "shell.execute_reply": "2025-05-15T05:05:28.221289Z",
     "shell.execute_reply.started": "2025-05-15T05:05:27.714700Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecfd-e640-4527-99d4-cb3cec9093b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.225263Z",
     "iopub.status.busy": "2025-05-15T05:05:28.224986Z",
     "iopub.status.idle": "2025-05-15T05:05:28.229028Z",
     "shell.execute_reply": "2025-05-15T05:05:28.228551Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.225244Z"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.p3.2xlarge\" # Override the instance type if you want to get a different container version\n",
    "\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7700-7c66-4af8-aea0-da0e5af493bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.229818Z",
     "iopub.status.busy": "2025-05-15T05:05:28.229595Z",
     "iopub.status.idle": "2025-05-15T05:05:28.256817Z",
     "shell.execute_reply": "2025-05-15T05:05:28.256241Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.229803Z"
    }
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.6.0\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a5e6f-73b8-4f66-8cd1-d2425bbaa911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.257729Z",
     "iopub.status.busy": "2025-05-15T05:05:28.257455Z",
     "iopub.status.idle": "2025-05-15T05:05:28.260450Z",
     "shell.execute_reply": "2025-05-15T05:05:28.259926Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.257712Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabb4d-b0b2-498c-95cb-41ed7d05ee65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:21.382486Z",
     "start_time": "2023-09-03T00:02:20.962208Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.261328Z",
     "iopub.status.busy": "2025-05-15T05:05:28.261076Z",
     "iopub.status.idle": "2025-05-15T05:05:28.542944Z",
     "shell.execute_reply": "2025-05-15T05:05:28.542457Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.261312Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import Compute, InputData, OutputDataConfig, SourceCode, StoppingCondition\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "\n",
    "# Define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"train.py\",\n",
    ")\n",
    "\n",
    "# Define the compute\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    keep_alive_period_in_seconds=0,\n",
    "    volume_size_in_gb=50\n",
    ")\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f\"train-{model_id.split('/')[-1].replace('.', '-')}-sft-script\"\n",
    "\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "# Define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    distributed=Torchrun(),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=7200\n",
    "    ),\n",
    "    hyperparameters={\n",
    "        \"config\": \"/opt/ml/input/data/config/args.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=output_path\n",
    "    ),\n",
    "    environment={\n",
    "        \"PYTORCH_CUDA_ALLOC_CONF\": \"expandable_segments:True\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a386bd9-172c-485c-af45-ebc1d126470b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.543852Z",
     "iopub.status.busy": "2025-05-15T05:05:28.543599Z",
     "iopub.status.idle": "2025-05-15T05:05:28.548759Z",
     "shell.execute_reply": "2025-05-15T05:05:28.548285Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.543835Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "# Pass the input data\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "test_input = InputData(\n",
    "    channel_name=\"test\",\n",
    "    data_source=test_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "config_input = InputData(\n",
    "    channel_name=\"config\",\n",
    "    data_source=train_config_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "# Check input channels configured\n",
    "data = [train_input, test_input, config_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e13aa-1df2-43fc-bae4-15f5b7113191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T05:05:28.549538Z",
     "iopub.status.busy": "2025-05-15T05:05:28.549329Z",
     "iopub.status.idle": "2025-05-15T06:10:00.904422Z",
     "shell.execute_reply": "2025-05-15T06:10:00.903797Z",
     "shell.execute_reply.started": "2025-05-15T05:05:28.549522Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "model_trainer.train(input_data_config=data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81686e-d27f-4c7b-bec6-f596e7dbaa32",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328b8fd-737d-4555-9824-56de5e202825",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "In the following sections, we are going to deploy the fine-tuned model on an Amazon SageMaker Real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb892b35-ab33-4964-9947-f9487a1e50cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50ff8a-842c-45bc-aa55-4a5e87f2b190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:08.515277Z",
     "start_time": "2023-11-20T18:41:08.503555Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:00.915160Z",
     "iopub.status.busy": "2025-05-15T06:10:00.914773Z",
     "iopub.status.idle": "2025-05-15T06:10:00.917671Z",
     "shell.execute_reply": "2025-05-15T06:10:00.917197Z",
     "shell.execute_reply.started": "2025-05-15T06:10:00.915141Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abfc30-b9f0-4cd2-8c2e-99bb77c80767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:00.918536Z",
     "iopub.status.busy": "2025-05-15T06:10:00.918287Z",
     "iopub.status.idle": "2025-05-15T06:10:00.945613Z",
     "shell.execute_reply": "2025-05-15T06:10:00.945092Z",
     "shell.execute_reply.started": "2025-05-15T06:10:00.918513Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35481eff-1142-46f3-8e38-50a1bdadba7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:00.947606Z",
     "iopub.status.busy": "2025-05-15T06:10:00.947349Z",
     "iopub.status.idle": "2025-05-15T06:10:01.231632Z",
     "shell.execute_reply": "2025-05-15T06:10:01.231021Z",
     "shell.execute_reply.started": "2025-05-15T06:10:00.947589Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}-sft-script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed118e7-1c80-4392-8ea5-147b63fc2f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.232563Z",
     "iopub.status.busy": "2025-05-15T06:10:01.232304Z",
     "iopub.status.idle": "2025-05-15T06:10:01.238175Z",
     "shell.execute_reply": "2025-05-15T06:10:01.237602Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.232546Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Prepare the search parameters\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Operator': 'Contains',\n",
    "                        'Value': job_name_prefix\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'TrainingJobStatus',\n",
    "                        'Operator': 'Equals',\n",
    "                        'Value': \"Completed\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        # Add NextToken if we have one\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        # Make the search request\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        # Filter and add matching jobs\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        # Check if we have more results to fetch\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:  # Stop if we found at least one match or no more results\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4e9bd-de61-4806-b314-6bcf988a2c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.239123Z",
     "iopub.status.busy": "2025-05-15T06:10:01.238809Z",
     "iopub.status.idle": "2025-05-15T06:10:01.436983Z",
     "shell.execute_reply": "2025-05-15T06:10:01.436464Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.239094Z"
    }
   },
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeba4b-cfc9-4aae-be86-8d2f3c4e5cb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ef485-b13b-43a7-a523-eacbdddbb81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.441096Z",
     "iopub.status.busy": "2025-05-15T06:10:01.440915Z",
     "iopub.status.idle": "2025-05-15T06:10:01.443601Z",
     "shell.execute_reply": "2025-05-15T06:10:01.443120Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.441080Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f2d8-b3b3-4b27-a0d2-e49812f56a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.444565Z",
     "iopub.status.busy": "2025-05-15T06:10:01.444233Z",
     "iopub.status.idle": "2025-05-15T06:10:01.447661Z",
     "shell.execute_reply": "2025-05-15T06:10:01.447196Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.444539Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f062e4-e829-40f4-a613-bf16ad503829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.448620Z",
     "iopub.status.busy": "2025-05-15T06:10:01.448233Z",
     "iopub.status.idle": "2025-05-15T06:10:01.473307Z",
     "shell.execute_reply": "2025-05-15T06:10:01.472771Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.448603Z"
    }
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"latest\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd6ef9-484a-4234-ba92-3c0ef95ccad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.474175Z",
     "iopub.status.busy": "2025-05-15T06:10:01.473938Z",
     "iopub.status.idle": "2025-05-15T06:10:01.500598Z",
     "shell.execute_reply": "2025-05-15T06:10:01.500055Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.474158Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if default_prefix:\n",
    "    model_data=f\"s3://{bucket_name}/{default_prefix}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    model_data=f\"s3://{bucket_name}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'OPTION_TRUST_REMOTE_CODE': 'true',\n",
    "        'OPTION_ROLLING_BATCH': \"vllm\",\n",
    "        'OPTION_DTYPE': 'bf16',\n",
    "        'OPTION_QUANTIZE': 'fp8',\n",
    "        'OPTION_TENSOR_PARALLEL_DEGREE': 'max',\n",
    "        'OPTION_MAX_ROLLING_BATCH_SIZE': '32',\n",
    "        'OPTION_MODEL_LOADING_TIMEOUT': '3600',\n",
    "        'OPTION_MAX_MODEL_LEN': '4096'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30036f-9231-4de4-a03f-1297d2b6a5a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.501483Z",
     "iopub.status.busy": "2025-05-15T06:10:01.501243Z",
     "iopub.status.idle": "2025-05-15T06:10:01.504515Z",
     "shell.execute_reply": "2025-05-15T06:10:01.503984Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.501465Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-sft-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9035076-ac69-4859-9824-dcbf07c0f2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-15T06:10:01.505349Z",
     "iopub.status.busy": "2025-05-15T06:10:01.505081Z",
     "iopub.status.idle": "2025-05-15T06:20:06.403975Z",
     "shell.execute_reply": "2025-05-15T06:20:06.403423Z",
     "shell.execute_reply.started": "2025-05-15T06:10:01.505333Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d0cac-4af1-4034-9f88-35861396c228",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6e8c1-5a3b-459f-8763-febab2b8f094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.408710Z",
     "iopub.status.busy": "2025-05-15T06:20:06.408433Z",
     "iopub.status.idle": "2025-05-15T06:20:06.411774Z",
     "shell.execute_reply": "2025-05-15T06:20:06.411254Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.408684Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625af54c-198f-4a1a-8bf7-8e6d8dcfa460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.412783Z",
     "iopub.status.busy": "2025-05-15T06:20:06.412517Z",
     "iopub.status.idle": "2025-05-15T06:20:06.441421Z",
     "shell.execute_reply": "2025-05-15T06:20:06.440875Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.412756Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61094a1-1fa9-495f-8343-aa27d9c4ba2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.443587Z",
     "iopub.status.busy": "2025-05-15T06:20:06.443346Z",
     "iopub.status.idle": "2025-05-15T06:20:06.446246Z",
     "shell.execute_reply": "2025-05-15T06:20:06.445773Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.443571Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-sft-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b040d-b8f4-4be0-9687-b28eff520236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.447237Z",
     "iopub.status.busy": "2025-05-15T06:20:06.446878Z",
     "iopub.status.idle": "2025-05-15T06:20:06.450070Z",
     "shell.execute_reply": "2025-05-15T06:20:06.449605Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.447209Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b03ad-a4aa-4107-be89-5d1160cd2d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.451056Z",
     "iopub.status.busy": "2025-05-15T06:20:06.450713Z",
     "iopub.status.idle": "2025-05-15T06:20:06.453917Z",
     "shell.execute_reply": "2025-05-15T06:20:06.453454Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.451031Z"
    }
   },
   "outputs": [],
   "source": [
    "base_prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \n",
    "Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{{question}}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19bb461-4995-465a-a5ae-0c13c067180d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.454822Z",
     "iopub.status.busy": "2025-05-15T06:20:06.454532Z",
     "iopub.status.idle": "2025-05-15T06:20:06.458319Z",
     "shell.execute_reply": "2025-05-15T06:20:06.457854Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.454797Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = base_prompt.format(\n",
    "    question=\"A 3-week-old child has been diagnosed with late onset perinatal meningitis, and the CSF culture shows gram-positive bacilli. What characteristic of this bacterium can specifically differentiate it from other bacterial agents?\"\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586b889-6554-4d75-b295-e7dc99673cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T06:20:06.459302Z",
     "iopub.status.busy": "2025-05-15T06:20:06.458933Z",
     "iopub.status.idle": "2025-05-15T06:20:26.572506Z",
     "shell.execute_reply": "2025-05-15T06:20:26.571897Z",
     "shell.execute_reply.started": "2025-05-15T06:20:06.459277Z"
    }
   },
   "outputs": [],
   "source": [
    "response = predictor.predict({\n",
    "\t\"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"stop\": ['<|eot_id|>']\n",
    "    }\n",
    "})\n",
    "\n",
    "response = response[\"generated_text\"].split(\"<|eot_id|>\")[0]\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb550225-a5b8-4695-bd89-f785ba547f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
