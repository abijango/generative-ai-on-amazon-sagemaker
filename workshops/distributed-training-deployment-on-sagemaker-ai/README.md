# Distributed Training and Deployment on SageMaker AI

> This content is available in [Distributed Training and Deployment on SageMaker AI ]. The below represents a synopsis of the content you will find by following the provided link.
> Welcome to the "Distributed Training and Deployment on SageMaker AI " workshop! This publicly available, hands-on experience is designed for data scientists who are ready to harness the power of Large Language Models (LLMs) and experiment different customization techniques on AWS.

In this workshop, you'll dive into different fine-tuning techniques, deployment options, and evaluation by leveraging SageMaker AI capabilities!

By the end of this workshop, you'll be able to:

- Understand how to prepare datasets for different type of model customization techniques
- Run fine-tuning workloads by leveraging SageMaker AI capabilities
- Deploy and test your fine-tuned model

## Workshop Content

1. Solution 1: Large scale distributed training for Data/ML engineers using Amazon SageMaker JumpStart
2. Solution 2: Large scale distributed training for Resident Data Scientist using Amazon SageMaker Training
   1. Option 1: Continued pre-training of LLMs using Amazon SageMaker Training
   2. Option 2: Supervised fine-tuning of LLMs using Amazon SageMaker Training
3. Solution 3: Large scale distributed training for Researchers using Amazon SageMaker Hyperpod with EKS integration

## How to run the workshop

This workshop follows a hands-on, self-paced format. Each module contains Jupyter notebooks and code that you'll run in your own JupyterLab or Code Editor environment.

**⚠️ Important**: Solution 3 requires an Amazon SageMaker Hyperpod with EKS cluster up and running in your AWS account.

- Step-by-step instructions and explanations
- Code samples that you can run and modify
- Links to additional resources
