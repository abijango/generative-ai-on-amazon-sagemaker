{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker RAG retrieval and generation with SageMaker Inference and Bedrock Guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab demonstrates how to enhance a Retrieval-Augmented Generation (RAG) pipeline by integrating Amazon SageMaker Inference with Amazon Bedrock Guardrails. We will walk through the process of querying a OpenSearch vector knowledge base, using SageMaker for model inference, applying Guardrails to control the generation of responses, and filtering results with metadata to ensure compliance and quality. We will use the same PubMed medical theme generated in the opensearch RAG lab where we will refer to the previously created opensearch vector database with PubMed dataset and show how guardrails can be used to filter the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This workshop lab guides you through building a secure and compliant Retrieval-Augmented Generation (RAG) pipeline using Amazon SageMaker for inference, OpenSearch for vector-based retrieval, and Amazon Bedrock Guardrails for response filtering. You will learn to:\n",
    "- Configure your AWS environment and required libraries.\n",
    "- Set up and publish Bedrock Guardrails to enforce compliance, safety, and contextual relevance.\n",
    "- Connect and query an AWS OpenSearch vector database populated with PubMed medical data (See lab 03 sagemaker-opensearch-rag for the opensearch database used in this lab).\n",
    "- Integrate SageMaker endpoints for language model inference. (See lab 03 sagemaker-opensearch-rag for the sagemaker endpoint details which are reused here.)\n",
    "- Apply guardrails to restrict inappropriate, unsafe, or non-compliant outputs, including blocking certain topics and anonymizing sensitive information.\n",
    "- Validate the effectiveness of guardrails using real-world medical and compliance scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Pre-requisites\n",
    "- Completion of previous labs (especially OpenSearch RAG ingestion).\n",
    "- Access to AWS SageMaker, OpenSearch, and appropriate IAM permissions.\n",
    "- Installation of Python libraries: opensearch-py, langchain, boto3, requests_aws4auth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries \n",
    "Prepare your environment with all necessary libraries and AWS credentials.\n",
    "- Install the required Python libraries by running the provided pip install commands for langchain, boto3, opensearch-py, requests-aws4auth, and certifi.\n",
    "- Import all necessary modules (boto3, json, etc.).\n",
    "- Confirm that your AWS credentials and permissions are set up, and that you have access to the required SageMaker and OpenSearch resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain boto3 -q\n",
    "%pip install opensearch-py\n",
    "%pip install requests-aws4auth\n",
    "%pip install certifi\n",
    "print(\"Installs completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError, BotoCoreError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set configuration variables\n",
    "Set up all configuration variables for OpenSearch and SageMaker. Note `%store -r variable_name` retrieves a previously stored variable from previous labs.\n",
    "You will replace the placeholder values for:\n",
    "   - `aos_host` with your OpenSearch domain endpoint (note: without `https://`).\n",
    "   - `index_name` with the name of your OpenSearch index from the ingestion lab.\n",
    "   - `SAGEMAKER_LLM_ENDPOINT_NAME` with your SageMaker endpoint name.\n",
    "- Initialize your AWS session and retrieve your IAM role ARN and region.\n",
    "- Initialize the Bedrock client for your AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r OS_DOMAIN_NAME\n",
    "%store -r AOS_HOST\n",
    "%store -r OPENSEARCH_INDEX_NAME\n",
    "%store -r EMBEDDING_MODEL_NAME\n",
    "%store -r EMBED_ENDPOINT_NAME\n",
    "%store -r GENERATION_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"OS_DOMAIN_NAME:{OS_DOMAIN_NAME}\")\n",
    "print(f\"AOS_HOST:{AOS_HOST}\")\n",
    "print(f\"OPENSEARCH_INDEX_NAME:{OPENSEARCH_INDEX_NAME}\")\n",
    "print(f\"EMBEDDING_MODEL_NAME:{EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"EMBED_ENDPOINT_NAME:{EMBED_ENDPOINT_NAME}\")\n",
    "print(f\"GENERATION_ENDPOINT_NAME:{GENERATION_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opensearch Configuration\n",
    "OPENSEARCH_URL = f\"https://{AOS_HOST}\"\n",
    "service = \"es\"  \n",
    "port = 443 \n",
    "\n",
    "# Sagemaker configuration\n",
    "session = boto3.Session()\n",
    "sts_client = boto3.client('sts')\n",
    "# Get caller identity\n",
    "caller_identity = sts_client.get_caller_identity()\n",
    "\n",
    "# Extract and print the IAM role ARN\n",
    "iam_role_arn = caller_identity[\"Arn\"]\n",
    "account_id = sts_client.get_caller_identity().get('Account')\n",
    "region = session.region_name\n",
    "\n",
    "print(\"Session's IAM Role ARN:\", iam_role_arn)\n",
    "\n",
    "# Initialize the Amazon Bedrock client in the region\n",
    "bedrock = boto3.client('bedrock', region_name=region)\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Amazon Bedrock Guardrails\n",
    "\n",
    "Bedrock Guardrails enable us to define policies that restrict or modify model responses based on compliance, safety, and contextual relevance. In this section you will define policies to control and filter model responses for compliance and safety.\n",
    "\n",
    "To implement guardrails in the RAG pipeline, we use Amazon Bedrock's API to programmatically define safety and compliance policies. Here's how these key functions work:\n",
    "- `bedrock.create_guardrail`: Defines policies to filter inappropriate content and enforce compliance in model responses.\n",
    "- `bedrock.create_guardrail_version`: Publishes a guardrail configuration for deployment.\n",
    "\n",
    "Implementation Workflow\n",
    "1. Create bedrock Guardrail: Define policies using create_guardrail\n",
    "2. Version Management: Publish with create_guardrail_version\n",
    "3. Attach the bedrock guardrail to the Inference step.\n",
    "\n",
    "Together this configuration ensures all RAG inference interactions:\n",
    "- Block requests for unverified treatments\n",
    "- Anonymize patient identifiers\n",
    "- Filter speculative medical claims\n",
    "- Maintain audit trails for compliance\n",
    "\n",
    "See AWS Bedrock Guardrails documentation for more details: https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-components.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create a Guardrail\n",
    "You will first create a AWS Bedrock guardrail with the following policies: \n",
    "- Topic-based restrictions: Block non-medical advice, misinformation, and unsupported cure claims.\n",
    "- Content filtering: Block hate, insults, sexual content, violence, misconduct, and prompt injection. Supported strength levels: NONE|LOW|MEDIUM|HIGH\n",
    "- Contextual grounding: Ensure answers are relevant to PubMed data.\n",
    "- Word filtering: Block specific sensitive or misleading terms.\n",
    "- Sensitive data anonymization: Automatically anonymize PII and sensitive medical data using entity types and regex patterns.\n",
    "\n",
    "After you execute the code block in this section please note the printed Guardrail ID, ARN, and version for later use.\n",
    "\n",
    "Note: To perform AWS Bedrock guardrail operations the IAM role will need the managed policy `arn:aws:iam::aws:policy/AmazonBedrockFullAccess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique client request token\n",
    "client_request_token = str(uuid.uuid4())\n",
    "\n",
    "# Create a Guardrail with specific filtering and compliance policies for medical use-case\n",
    "response = bedrock.create_guardrail(\n",
    "    name=\"MedicalContextGuardrails\",\n",
    "    description=\"Restrict responses to PubMed-based medical content only\",\n",
    "    blockedInputMessaging=\"This request cannot be processed due to safety protocols.\",\n",
    "    blockedOutputsMessaging=\"Response blocked per compliance guidelines.\",\n",
    "\n",
    "    # Topic-based restrictions (e.g., denying non-medical advice)\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {'name': 'non-medical-advice', 'definition': 'Any recommendations outside medical expertise or context', 'type': 'DENY'},\n",
    "            {'name': 'misinformation', 'definition': 'Dissemination of inaccurate or unverified medical information', 'type': 'DENY'},\n",
    "            {'name': 'medical-cure-claims', 'definition': 'Claims of guaranteed or definitive cures for medical conditions without sufficient evidence', 'type': 'DENY'}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Content filtering policies (e.g., blocking harmful or unethical content)\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {'type': 'HATE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'INSULTS', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'SEXUAL', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'VIOLENCE', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'MISCONDUCT', 'inputStrength': 'HIGH', 'outputStrength': 'HIGH'},\n",
    "            {'type': 'PROMPT_ATTACK', 'inputStrength': 'HIGH', 'outputStrength': 'NONE'}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Contextual grounding policies ensuring relevance to PubMed-based embeddings\n",
    "    contextualGroundingPolicyConfig={\n",
    "        # Ensure responses are grounded in the embeddings loaded from PubMed articles\n",
    "        'filtersConfig': [\n",
    "            {'type': 'GROUNDING', 'threshold': 0.1},\n",
    "            {'type': 'RELEVANCE', 'threshold': 0.1}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # List of restricted words related to sensitive medical topics\n",
    "    wordPolicyConfig={\n",
    "        # Example: blocking inappropriate usage of critical medical terms\n",
    "        'wordsConfig': [\n",
    "            {'text': \"malpractice\"}, {'text': \"misdiagnosis\"}, {'text': \"unauthorized treatment\"},\n",
    "            {'text': \"experimental drug\"}, {'text': \"unapproved therapy\"}, {'text': \"medical fraud\"},\n",
    "            {'text': \"cure\"}, {'text': \"guaranteed cure\"}, {'text': \"permanent remission\"}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Sensitive data anonymization (e.g., patient information)\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        # Anonymize identifiable patient information\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': \"NAME\", \"action\": \"ANONYMIZE\"}, {'type': \"EMAIL\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"PHONE\", \"action\": \"ANONYMIZE\"}, {'type': \"US_SOCIAL_SECURITY_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"ADDRESS\", \"action\": \"ANONYMIZE\"}, {'type': \"CA_HEALTH_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"PASSWORD\", \"action\": \"ANONYMIZE\"}, {'type': \"IP_ADDRESS\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"CA_SOCIAL_INSURANCE_NUMBER\", \"action\": \"ANONYMIZE\"}, {'type': \"CREDIT_DEBIT_CARD_NUMBER\", \"action\": \"ANONYMIZE\"},\n",
    "            {'type': \"AGE\", \"action\": \"ANONYMIZE\"}, {'type': \"US_BANK_ACCOUNT_NUMBER\", \"action\": \"ANONYMIZE\"}\n",
    "        ],\n",
    "        # Example regex patterns for anonymizing sensitive medical data\n",
    "        'regexesConfig': [\n",
    "            {\n",
    "                \"name\": \"medical_procedure_code\",\n",
    "                \"description\": \"Pattern for medical procedure codes\",\n",
    "                \"pattern\": \"\\\\b[A-Z]{1,5}\\\\d{1,5}\\\\b\",\n",
    "                \"action\": \"ANONYMIZE\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"clinical_trial_id\",\n",
    "                \"description\": \"Pattern for clinical trial identifiers\",\n",
    "                \"pattern\": \"\\\\bNCT\\\\d{8}\\\\b\",\n",
    "                \"action\": \"ANONYMIZE\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Tags for environment tracking\n",
    "    tags=[\n",
    "        {\"key\": \"Environment\", \"value\": \"Production\"},\n",
    "        {\"key\": \"Department\", \"value\": \"Medical\"}\n",
    "    ],\n",
    "    clientRequestToken=client_request_token\n",
    ")\n",
    "\n",
    "# Retrieve and print the Guardrail ID, ARN, and version\n",
    "guardrail_id = response['guardrailId']\n",
    "print(f\"Guardrail ID: {guardrail_id}\")\n",
    "print(f\"Guardrail ARN: {response['guardrailArn']}\")\n",
    "print(f\"Version: {response['version']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create a Published Version of the Guardrail\n",
    "Now we will publish the created AWS Bedrock guadrail for use in inference. \n",
    "We will use the bedrock.create_guardrail_version command to publish your guardrail. \n",
    "Store the returned version identifier for use in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a published version\n",
    "version_response = bedrock.create_guardrail_version(\n",
    "    guardrailIdentifier=response['guardrailId'],\n",
    "    description=\"Production version 1.0\"\n",
    ")\n",
    "guardrail_version=version_response['version']\n",
    "guardrail_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define function to apply bedrock guardrail at inference\n",
    "Using the created AWS bedrock guardrials we will now create a function to apply guardrails to model outputs. We will create the function `apply_output_guardrail` which calls Bedrock Guardrails on the generated text and returns the filtered output. You will use this function after generating model responses in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_output_guardrail(output_text):\n",
    "    \"\"\"\n",
    "    Applies guardrail policies to filter and sanitize the output text from LLM responses.\n",
    "\n",
    "    This function processes the output text through defined guardrail policies to detect and\n",
    "    handle sensitive information, ensuring compliance with security and privacy requirements.\n",
    "    It can mask, anonymize, or block responses containing protected information like\n",
    "    health insurance IDs, personal identifiers, or other sensitive data.\n",
    "\n",
    "    Args:\n",
    "        output_text (str): The raw output text from the LLM response to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized output text with applied guardrail policies. If sensitive\n",
    "            information is detected, it will be masked or anonymized according to the\n",
    "            configured policies.\n",
    "\n",
    "    Raises:\n",
    "        GuardrailException: If there's an error in applying the guardrail policies.\n",
    "        ValueError: If the input text is None or empty.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nApply bedrock guardrails to the output using {guardrail_id} {guardrail_version}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Use only the parameters supported by your boto3 version\n",
    "        response = bedrock_client.apply_guardrail(\n",
    "            guardrailIdentifier=guardrail_id,\n",
    "            guardrailVersion=guardrail_version,\n",
    "            source='OUTPUT',\n",
    "            content=[\n",
    "                {\n",
    "                    'text': {\n",
    "                        'text': output_text\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Process response based on what fields are available\n",
    "        if 'outputs' in response and response['outputs']:\n",
    "            return response['outputs'][0]['text']\n",
    "        else:\n",
    "            return output_text\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Output guardrail application failed: {str(e)}\")\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Define SageMaker functions\n",
    "In this section we will set up SageMaker endpoint integration for LLM inference. We use the similar approach for OpenSearch retrieval and SageMaker inference as defined in the previous lab.\n",
    "- We begun by defining a custom ContentHandler for input/output formatting.\n",
    "- Initialize the SagemakerEndpoint object with your endpoint name, region, and content handler.\n",
    "- Prepare a prompt template for question-answering using context retrieved from OpenSearch.\n",
    "- Test the setup by running a sample question and context through the model and printing the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "from langchain_community.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        You are an assistant for question-answering tasks. Answer the following question using the provided context. If you don't know the answer, just say \"I don't know.\".\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        Context: {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        <|start_header_id|>assistant<|end_header_id|> \n",
    "        Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        #print(\"Input prompt:\", input_str)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        # Parse and extract generated text from response\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        #print(\"Raw response:\", response_json)  # Debugging\n",
    "        # Handle different response formats\n",
    "        return response_json[\"generated_text\"]\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "sagemaker_llm=SagemakerEndpoint(\n",
    "        endpoint_name=GENERATION_ENDPOINT_NAME,\n",
    "        region_name=region,\n",
    "        model_kwargs={\"temperature\": 1e-10, \"max_new_tokens\": 250},\n",
    "        content_handler=content_handler,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated prompt and context for medical question\n",
    "\n",
    "prompt = \"What is the role of mitochondrial dynamics in programmed cell death in lace plants?\"\n",
    "context_prompt = \"\"\"\n",
    "Based on research into Aponogeton madagascariensis (lace plant), programmed cell death (PCD) occurs in the cells at the center of areoles in leaves.\n",
    "The role of mitochondrial dynamics during this process is being investigated.\n",
    "\"\"\"\n",
    "\n",
    "input_prompt = PROMPT.format(question=prompt, context=context_prompt)\n",
    "\n",
    "# Invoke the model using the prompt\n",
    "response = sagemaker_llm(input_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OpenSearch retrieval \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define the OpenSearch vector database retrieval\n",
    "Connect to OpenSearch and prepare for vector-based retrieval. The steps followed are,\n",
    "- Set up OpenSearch authentication using your AWS credentials and the AWS4Auth class.\n",
    "- Initialize the OpenSearch client and verify the connection by listing available indices.\n",
    "- Initialize the sentence embedding model using HuggingFace Transformers (sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "Note: The IAM role used will need the managed permissions `arn:aws:iam::aws:policy/AmazonOpenSearchServiceFullAccess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "from transformers import pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenSearch using the IAM Role of this notebook\n",
    "credentials = boto3.Session().get_credentials()\n",
    "signerauth = AWSV4SignerAuth(credentials, region, \"es\")\n",
    "\n",
    "# Create OpenSearch client\n",
    "aos_client = OpenSearch(\n",
    "    hosts=[f\"https://{AOS_HOST}\"],\n",
    "    http_auth=signerauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=60\n",
    ")\n",
    "print(\"Connection details: \")\n",
    "aos_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test opensearch connection by listing indices\n",
    "try:\n",
    "    response = aos_client.indices.get_alias(\"*\")\n",
    "    print(\"Indices:\", response)\n",
    "except Exception as e:\n",
    "    print(\"Error connecting to OpenSearch:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from langchain_community.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain_community.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "\n",
    "class EmbedContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        \"\"\"\n",
    "        Transforms the input into bytes that can be consumed by SageMaker endpoint.\n",
    "        Args:\n",
    "            inputs: List of input strings.\n",
    "            model_kwargs: Additional keyword arguments to be passed to the endpoint.\n",
    "        Returns:\n",
    "            The transformed bytes input.\n",
    "        \"\"\"\n",
    "        # Example: inference.py expects a JSON string with a \"inputs\" key:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Transforms the bytes output from the endpoint into a list of embeddings.\n",
    "        Args:\n",
    "            output: The bytes output from SageMaker endpoint.\n",
    "        Returns:\n",
    "            The transformed output - list of embeddings\n",
    "        Note:\n",
    "            The length of the outer list is the number of input strings.\n",
    "            The length of the inner lists is the embedding dimension.\n",
    "        \"\"\"\n",
    "        # Example: inference.py returns a JSON string with the list of\n",
    "        # embeddings in a \"vectors\" key:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        # print(len(response_json))\n",
    "        return response_json\n",
    "\n",
    "\n",
    "embed_content_handler = EmbedContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, embed_endpoint_name, model_kwargs=None):\n",
    "    \"\"\"\n",
    "    Call the SageMaker embedding model to embed the given text.\n",
    "    Adjust the payload and response parsing according to your model's API.\n",
    "    \"\"\"\n",
    "    embeddings = SagemakerEndpointEmbeddings(\n",
    "        endpoint_name=embed_endpoint_name,\n",
    "        region_name=region,\n",
    "        content_handler=embed_content_handler,\n",
    "    )\n",
    "\n",
    "    return embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# RAG retrieval function\n",
    "def retrieve_context(query, k=3):\n",
    "    query_embedding = get_embedding(query, EMBED_ENDPOINT_NAME)\n",
    "    \n",
    "    search_body = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"context_vector\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"k\": k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = aos_client.search(\n",
    "        index=OPENSEARCH_INDEX_NAME,\n",
    "        body=search_body\n",
    "    )\n",
    "    \n",
    "    return [hit[\"_source\"]['contexts'] for hit in response[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve relevant context\n",
    "query = \" what are the key components of phonological processing that are believed to influence \\\n",
    "reading levels in individuals who have undergone cerebral hemispherectomy procedure?\"\n",
    "contexts = retrieve_context(query)\n",
    "print(\"Retrieved context:\", contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Retrieve context for input prompt\n",
    "Retrieve relevant context for a query using vector search.\n",
    "- Use the `retrieve_context` function to generate an embedding for the input query and perform a k-NN search in OpenSearch.\n",
    "- The function returns the top-k most relevant context passages.\n",
    "- Test the retrieval by running a sample query and printing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_vector_context(input_query):\n",
    "    # Retrieve relevant context\n",
    "    query = \"What is Amazon?\"\n",
    "    contexts = retrieve_context(input_query)\n",
    "    \n",
    "    for context in contexts:\n",
    "        print(\"\\nRetrieved context: \", context)\n",
    "\n",
    "    # Handle empty or single returned list\n",
    "    if contexts:\n",
    "        context_prompt = contexts[0] if len(contexts) > 0 else None\n",
    "    else:\n",
    "        context_prompt = None\n",
    "    \n",
    "    return context_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate inference results with Bedrock guardrails\n",
    "Now we use the inference and guardrails setup in the previous sections to demonstrate how guardrails block unsafe responses, block non-compliant responses, restrict anonymize information and block sensitive information for RAG inferences. The workflow followed is,\n",
    "- Input a query that should trigger a guardrail (e.g., \"Is there a guaranteed cure for Alzheimer's disease based on the latest research?\").\n",
    "- Retrieve relevant context using OpenSearch.\n",
    "- Format the prompt and run inference through SageMaker.\n",
    "- Print the initial (unfiltered) response.\n",
    "- Apply the guardrail function and print the filtered response, which should display the preconfigured guardrail message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Restrict reponse based on blocked content/topic\n",
    "\n",
    "In this example you'll test the guardrail's ability to block responses related to cures for diseases without sufficient evidence.\n",
    "\n",
    "When prompted  \"Is there a cure for HIV based on the latest research?\" the base model responds with \"No\", which is correct, but in this scenario the model shouldn't provide any affirmative answers related to cures per compliance guidlines. \n",
    "\n",
    "Therefore the guardrail should block the response and respond with \"Response blocked per compliance guidelines.\". You could additionally apply this guardrail on the input, blocking the request from ever making it to the generation model to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query that will be sent to the model\n",
    "query = \"Is there a cure for HIV based on the latest research?\"\n",
    "\n",
    "# Retrieve relevant context from the OpenSearch based on the query\n",
    "# TODO Update the context retrieval function\n",
    "context_prompt = get_opensearch_vector_context(query)  # Replace with your OpenSearch retrieval\n",
    "\n",
    "input_prompt = PROMPT.format(question=query, context=context_prompt)\n",
    "\n",
    "# Invoke the model using the prompt\n",
    "raw_response = sagemaker_llm(input_prompt)\n",
    "print(\"\\n\\n Initial response without guardrails: \", raw_response)\n",
    "\n",
    "guardrail_response = apply_output_guardrail(raw_response)\n",
    "\n",
    "# Print the user's query\n",
    "print(\"\\n\\n User's query: \", query)  # Use the variable directly, not a dictionary\n",
    "\n",
    "# Print the generated answer from the model based on the query and context\n",
    "print(\"\\n\\n Answer with guardrails: \", guardrail_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Restrict reponse based on PII Data\n",
    "\n",
    "This example shows a simple redaction of content coming back from the generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query that will be sent to the model\n",
    "query = \"Can you provide the contact information, including the phone number and email address, for Dr. Vivek Murthy, who led the clinical trial NCT12345678?\"\n",
    "\n",
    "# Retrieve relevant context from the OpenSearch based on the query\n",
    "# TODO Update the context retrieval function\n",
    "context_prompt = get_opensearch_vector_context(query) # Replace with your OpenSearch retrieval\n",
    "\n",
    "input_prompt = PROMPT.format(question=query, context=context_prompt)\n",
    "\n",
    "# Invoke the model using the prompt\n",
    "raw_response = sagemaker_llm(input_prompt)\n",
    "print(\"\\n\\nInitial response without guardrails: \", raw_response)\n",
    "\n",
    "guardrail_response = apply_output_guardrail(raw_response)\n",
    "\n",
    "# Print the user's query\n",
    "print(\"\\n\\nUser's query: \", query) # Use the variable directly, not a dictionary\n",
    "\n",
    "# Print the generated answer from the model based on the query and context, with applying the guardrails\n",
    "print(\"\\n\\nAnswer with guardrails: \", guardrail_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "By the end of this lab, you will have:\n",
    "- Configured a secure, compliant RAG pipeline using AWS services.\n",
    "- Learned how to enforce strict guardrails for safety, compliance, and relevance in medical AI applications.\n",
    "- Practiced integrating vector retrieval, LLM inference, and response filtering in a real-world workflow.\n",
    "\n",
    "`Next Steps`: Experiment with your own queries and adjust guardrail policies to fit other compliance or safety requirements in your domain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
